% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2016, pp. 770--778.

\bibitem{huang2017densely}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, and K.~Q. Weinberger, ``Densely connected
  convolutional networks,'' in \emph{Proceedings of the IEEE Conference on
  Computer Vision and Pattern Recognition}, 2017, pp. 4700--4708.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~25, pp. 1097--1105, 2012.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich, ``Going deeper with convolutions,'' in
  \emph{Proceedings of the IEEE conference on computer vision and pattern
  recognition}, 2015, pp. 1--9.

\bibitem{girshick2015fast}
R.~Girshick, ``Fast r-cnn,'' in \emph{Proceedings of the IEEE international
  conference on computer vision}, 2015, pp. 1440--1448.

\bibitem{ren2015faster}
S.~Ren, K.~He, R.~Girshick, and J.~Sun, ``Faster r-cnn: Towards real-time
  object detection with region proposal networks,'' \emph{Advances in neural
  information processing systems}, vol.~28, pp. 91--99, 2015.

\bibitem{liu2016ssd}
W.~Liu, D.~Anguelov, D.~Erhan, C.~Szegedy, S.~Reed, C.-Y. Fu, and A.~C. Berg,
  ``Ssd: Single shot multibox detector,'' in \emph{European conference on
  computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2016, pp.
  21--37.

\bibitem{redmon2016you}
J.~Redmon, S.~Divvala, R.~Girshick, and A.~Farhadi, ``You only look once:
  Unified, real-time object detection,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2016, pp. 779--788.

\bibitem{xie2015holistically}
S.~Xie and Z.~Tu, ``Holistically-nested edge detection,'' in \emph{Proceedings
  of the IEEE international conference on computer vision}, 2015, pp.
  1395--1403.

\bibitem{chen2017deeplab}
L.-C. Chen, G.~Papandreou, I.~Kokkinos, K.~Murphy, and A.~L. Yuille, ``Deeplab:
  Semantic image segmentation with deep convolutional nets, atrous convolution,
  and fully connected crfs,'' \emph{IEEE transactions on pattern analysis and
  machine intelligence}, vol.~40, no.~4, pp. 834--848, 2017.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick, ``Mask r-cnn,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2961--2969.

\bibitem{long2015fully}
J.~Long, E.~Shelhamer, and T.~Darrell, ``Fully convolutional networks for
  semantic segmentation,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2015, pp. 3431--3440.

\bibitem{toshev2014human}
A.~Toshev and C.~Szegedy, ``Human pose estimation via deep neural
  networks’,'' \emph{CVPR.(Columbus, Ohio, 2014)}, pp. 1653--1660, 2014.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, ``Learning multiple layers of features from tiny images,''
  \emph{Master's thesis, University of Tront}, 2009.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei, ``Imagenet: A
  large-scale hierarchical image database,'' in \emph{2009 IEEE conference on
  computer vision and pattern recognition}.\hskip 1em plus 0.5em minus
  0.4em\relax Ieee, 2009, pp. 248--255.

\bibitem{tan2019mnasnet}
M.~Tan, B.~Chen, R.~Pang, V.~Vasudevan, M.~Sandler, A.~Howard, and Q.~V. Le,
  ``Mnasnet: Platform-aware neural architecture search for mobile,'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition}, 2019, pp. 2820--2828.

\bibitem{dong2019searching}
X.~Dong and Y.~Yang, ``Searching for a robust neural architecture in four gpu
  hours,'' in \emph{Proceedings of the IEEE Conference on computer vision and
  pattern recognition}, 2019, pp. 1761--1770.

\bibitem{zhang2020one}
M.~Zhang, H.~Li, S.~Pan, X.~Chang, C.~Zhou, Z.~Ge, and S.~Su, ``One-shot neural
  architecture search: Maximising diversity to overcome catastrophic
  forgetting,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, vol.~43, no.~9, pp. 2921--2935, 2021.

\bibitem{cai2018proxylessnas}
H.~Cai, L.~Zhu, and S.~Han, ``Proxylessnas: Direct neural architecture search
  on target task and hardware,'' in \emph{International Conference on Learning
  Representations}, 2019.

\bibitem{lu2020neural}
Z.~Lu, G.~Sreekumar, E.~Goodman, W.~Banzhaf, K.~Deb, and V.~N. Boddeti,
  ``Neural architecture transfer,'' \emph{IEEE Trans. Pattern Anal. Mach.
  Intell.}, vol.~43, no.~9, pp. 2971--2989, 2021.

\bibitem{baker2016designing}
B.~Baker, O.~Gupta, N.~Naik, and R.~Raskar, ``Designing neural network
  architectures using reinforcement learning,'' \emph{arXiv preprint
  arXiv:1611.02167}, 2016.

\bibitem{zoph2018learning}
B.~Zoph, V.~Vasudevan, J.~Shlens, and Q.~V. Le, ``Learning transferable
  architectures for scalable image recognition,'' in \emph{Proceedings of the
  IEEE conference on computer vision and pattern recognition}, 2018, pp.
  8697--8710.

\bibitem{real2017large}
E.~Real, S.~Moore, A.~Selle, S.~Saxena, Y.~L. Suematsu, J.~Tan, Q.~V. Le, and
  A.~Kurakin, ``Large-scale evolution of image classifiers,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2017, pp. 2902--2911.

\bibitem{real2019aging}
E.~Real, A.~Aggarwal, Y.~Huang, and Q.~V. Le, ``Aging evolution for image
  classifier architecture search,'' in \emph{AAAI conference on artificial
  intelligence}, vol.~2, 2019.

\bibitem{xu2021partially}
Y.~Xu, L.~Xie, W.~Dai, X.~Zhang, X.~Chen, G.-J. Qi, H.~Xiong, and Q.~Tian,
  ``Partially-connected neural architecture search for reduced computational
  redundancy,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, vol.~43, no.~9, pp. 2953--2970, 2021.

\bibitem{zoph2016neural}
B.~Zoph and Q.~V. Le, ``Neural architecture search with reinforcement
  learning,'' \emph{arXiv preprint arXiv:1611.01578}, 2016.

\bibitem{watkins1989learning}
C.~J. C.~H. Watkins, ``Learning from delayed rewards,'' \emph{King's College,
  Cambridge United Kingdom}, 1989.

\bibitem{zhong2018practical}
Z.~Zhong, J.~Yan, W.~Wu, J.~Shao, and C.-L. Liu, ``Practical block-wise neural
  network architecture generation,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2018, pp. 2423--2432.

\bibitem{zhong2020blockqnn}
Z.~Zhong, Z.~Yang, B.~Deng, J.~Yan, W.~Wu, J.~Shao, and C.-L. Liu, ``Blockqnn:
  Efficient block-wise neural network architecture generation,'' \emph{IEEE
  transactions on pattern analysis and machine intelligence}, vol.~43, no.~7,
  pp. 2314--2328, 2020.

\bibitem{schmitt2001theory}
L.~M. Schmitt, ``Theory of genetic algorithms,'' \emph{Theoretical Computer
  Science}, vol. 259, no. 1-2, pp. 1--61, 2001.

\bibitem{miller1995genetic}
B.~L. Miller, D.~E. Goldberg \emph{et~al.}, ``Genetic algorithms, tournament
  selection, and the effects of noise,'' \emph{Complex systems}, vol.~9, no.~3,
  pp. 193--212, 1995.

\bibitem{schaffer1992combinations}
J.~D. Schaffer, D.~Whitley, and L.~J. Eshelman, ``Combinations of genetic
  algorithms and neural networks: A survey of the state of the art,'' in
  \emph{[Proceedings] COGANN-92: International Workshop on Combinations of
  Genetic Algorithms and Neural Networks}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 1992, pp. 1--37.

\bibitem{yao1999evolving}
X.~Yao, ``Evolving artificial neural networks,'' \emph{Proceedings of the
  IEEE}, vol.~87, no.~9, pp. 1423--1447, 1999.

\bibitem{stanley2002evolving}
K.~O. Stanley and R.~Miikkulainen, ``Evolving neural networks through
  augmenting topologies,'' \emph{Evolutionary computation}, vol.~10, no.~2, pp.
  99--127, 2002.

\bibitem{inden2012evolving}
B.~Inden, Y.~Jin, R.~Haschke, and H.~Ritter, ``Evolving neural fields for
  problems with large input and output spaces,'' \emph{Neural Networks},
  vol.~28, pp. 24--39, 2012.

\bibitem{bengio2012practical}
Y.~Bengio, ``Practical recommendations for gradient-based training of deep
  architectures,'' in \emph{Neural networks: Tricks of the trade}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2012, pp. 437--478.

\bibitem{xie2017genetic}
L.~Xie and A.~Yuille, ``Genetic cnn,'' in \emph{Proceedings of the IEEE
  international conference on computer vision}, 2017, pp. 1379--1388.

\bibitem{miikkulainen2019evolving}
R.~Miikkulainen, J.~Liang, E.~Meyerson, A.~Rawal, D.~Fink, O.~Francon, B.~Raju,
  H.~Shahrzad, A.~Navruzyan, N.~Duffy \emph{et~al.}, ``Evolving deep neural
  networks,'' in \emph{Artificial intelligence in the age of neural networks
  and brain computing}.\hskip 1em plus 0.5em minus 0.4em\relax Elsevier, 2019,
  pp. 293--312.

\bibitem{liang2018evolutionary}
J.~Liang, E.~Meyerson, and R.~Miikkulainen, ``Evolutionary architecture search
  for deep multitask networks,'' in \emph{Proceedings of the Genetic and
  Evolutionary Computation Conference}, 2018, pp. 466--473.

\bibitem{suganuma2017genetic}
M.~Suganuma, S.~Shirakawa, and T.~Nagao, ``A genetic programming approach to
  designing convolutional neural network architectures,'' in \emph{Proceedings
  of the genetic and evolutionary computation conference}, 2017, pp. 497--504.

\bibitem{saxena2016convolutional}
S.~Saxena and J.~Verbeek, ``Convolutional neural fabrics,'' \emph{Advances in
  neural information processing systems}, vol.~29, 2016.

\bibitem{mitchell1998introduction}
M.~Mitchell, \emph{An introduction to genetic algorithms}.\hskip 1em plus 0.5em
  minus 0.4em\relax MIT press, 1998.

\bibitem{sun2019evolving}
Y.~Sun, B.~Xue, M.~Zhang, and G.~G. Yen, ``Evolving deep convolutional neural
  networks for image classification,'' \emph{IEEE Transactions on Evolutionary
  Computation}, vol.~24, no.~2, pp. 394--407, 2019.

\bibitem{9075201}
Y.~Sun, B.~Xue, M.~Zhang, G.~G. Yen, and J.~Lv, ``Automatically designing cnn
  architectures using the genetic algorithm for image classification,''
  \emph{IEEE Transactions on Cybernetics}, vol.~50, no.~9, pp. 3840--3854,
  2020.

\bibitem{8742788}
Y.~Sun, B.~Xue, M.~Zhang, and G.~G. Yen, ``Completely automated cnn
  architecture design based on blocks,'' \emph{IEEE Transactions on Neural
  Networks and Learning Systems}, vol.~31, no.~4, pp. 1242--1254, 2020.

\bibitem{9439793}
D.~O’Neill, B.~Xue, and M.~Zhang, ``Evolutionary neural architecture search
  for high-dimensional skip-connection structures on densenet style networks,''
  \emph{IEEE Transactions on Evolutionary Computation}, vol.~25, no.~6, pp.
  1118--1132, 2021.

\bibitem{zhang2021adaptive}
T.~Zhang, C.~Lei, Z.~Zhang, X.-B. Meng, and C.~P. Chen, ``As-nas: Adaptive
  scalable neural architecture search with reinforced evolutionary algorithm
  for deep learning,'' \emph{IEEE Transactions on Evolutionary Computation},
  vol.~25, no.~5, pp. 830--841, 2021.

\bibitem{liu2020block}
J.~Liu, S.~Zhou, Y.~Wu, K.~Chen, W.~Ouyang, and D.~Xu, ``Block proposal neural
  architecture search,'' \emph{IEEE Transactions on Image Processing}, vol.~30,
  pp. 15--25, 2020.

\bibitem{sun2018evolving}
Y.~Sun, G.~G. Yen, and Z.~Yi, ``Evolving unsupervised deep neural networks for
  learning meaningful representations,'' \emph{IEEE Transactions on
  Evolutionary Computation}, vol.~23, no.~1, pp. 89--103, 2018.

\bibitem{lu2019nsga}
Z.~Lu, I.~Whalen, V.~Boddeti, Y.~Dhebar, K.~Deb, E.~Goodman, and W.~Banzhaf,
  ``Nsga-net: neural architecture search using multi-objective genetic
  algorithm,'' in \emph{Proceedings of the Genetic and Evolutionary Computation
  Conference}, 2019, pp. 419--427.

\bibitem{lu2020multi}
Z.~Lu, I.~Whalen, Y.~Dhebar, K.~Deb, E.~D. Goodman, W.~Banzhaf, and V.~N.
  Boddeti, ``Multiobjective evolutionary design of deep convolutional neural
  networks for image classification,'' \emph{IEEE Transactions on Evolutionary
  Computation}, vol.~25, no.~2, pp. 277--291, 2020.

\bibitem{lu2021neural}
Z.~Lu, G.~Sreekumar, E.~Goodman, W.~Banzhaf, K.~Deb, and V.~N. Boddeti,
  ``Neural architecture transfer,'' \emph{IEEE Transactions on Pattern Analysis
  and Machine Intelligence}, vol.~43, no.~9, pp. 2971--2989, 2021.

\bibitem{guo2020single}
Z.~Guo, X.~Zhang, H.~Mu, W.~Heng, Z.~Liu, Y.~Wei, and J.~Sun, ``Single path
  one-shot neural architecture search with uniform sampling,'' in
  \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 544--560.

\bibitem{elsken2018efficient}
T.~Elsken, J.~H. Metzen, and F.~Hutter, ``Efficient multi-objective neural
  architecture search via lamarckian evolution,'' \emph{arXiv preprint
  arXiv:1804.09081}, 2018.

\bibitem{kim2017nemo}
Y.-H. Kim, B.~Reddy, S.~Yun, and C.~Seo, ``Nemo: Neuro-evolution with
  multiobjective optimization of deep neural network for speed and accuracy,''
  in \emph{ICML 2017 AutoML workshop}, 2017.

\bibitem{deb2002fast}
K.~Deb, A.~Pratap, S.~Agarwal, and T.~Meyarivan, ``A fast and elitist
  multiobjective genetic algorithm: Nsga-ii,'' \emph{IEEE transactions on
  evolutionary computation}, vol.~6, no.~2, pp. 182--197, 2002.

\bibitem{wen2021two}
Y.-W. Wen, S.-H. Peng, and C.-K. Ting, ``Two-stage evolutionary neural
  architecture search for transfer learning,'' \emph{IEEE Transactions on
  Evolutionary Computation}, vol.~25, no.~5, pp. 928--940, 2021.

\bibitem{zhu2019multi}
H.~Zhu and Y.~Jin, ``Multi-objective evolutionary federated learning,''
  \emph{IEEE Transactions on Neural Networks and Learning Systems}, vol.~31,
  no.~4, pp. 1310--1322, 2019.

\bibitem{zhu2021real}
------, ``Real-time federated evolutionary neural architecture search,''
  \emph{IEEE Transactions on Evolutionary Computation}, vol.~26, no.~2, pp.
  364--378, 2021.

\bibitem{zhu2021federatednas}
H.~Zhu, H.~Zhang, and Y.~Jin, ``From federated learning to federated neural
  architecture search: a survey,'' \emph{Complex \& Intelligent Systems},
  vol.~7, no.~2, pp. 639--657, 2021.

\bibitem{zhou2020econas}
D.~Zhou, X.~Zhou, W.~Zhang, C.~C. Loy, S.~Yi, X.~Zhang, and W.~Ouyang,
  ``Econas: Finding proxies for economical neural architecture search,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2020, pp. 11\,396--11\,404.

\bibitem{li2017hyperband}
L.~Li, K.~G. Jamieson, G.~DeSalvo, A.~Rostamizadeh, and A.~Talwalkar,
  ``Hyperband: Bandit-based configuration evaluation for hyperparameter
  optimization,'' in \emph{ICLR (Poster)}, 2017.

\bibitem{zhang2022evolutionary}
H.~Zhang, Y.~Jin, and K.~Hao, ``Evolutionary search for complete neural network
  architectures with partial weight sharing,'' \emph{IEEE Transactions on
  Evolutionary Computation}, 2022.

\bibitem{fang2020fna++}
J.~Fang, Y.~Sun, Q.~Zhang, K.~Peng, Y.~Li, W.~Liu, and X.~Wang, ``Fna++: Fast
  network adaptation via parameter remapping and architecture search,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~43, no.~9, pp. 2990--3004, 2020.

\bibitem{cai2019once}
H.~Cai, C.~Gan, T.~Wang, Z.~Zhang, and S.~Han, ``Once-for-all: Train one
  network and specialize it for efficient deployment,'' in \emph{International
  Conference on Learning Representations}, 2020.

\bibitem{zela2018towards}
A.~Zela, A.~Klein, S.~Falkner, and F.~Hutter, ``Towards automated deep
  learning: Efficient joint neural architecture and hyperparameter search,''
  \emph{arXiv preprint arXiv:1807.06906}, 2018.

\bibitem{yang2022accelerating}
S.~Yang, Y.~Tian, X.~Xiang, S.~Peng, and X.~Zhang, ``Accelerating evolutionary
  neural architecture search via multi-fidelity evaluation,'' \emph{IEEE
  Transactions on Cognitive and Developmental Systems}, 2022.

\bibitem{chrabaszcz2017downsampled}
P.~Chrabaszcz, I.~Loshchilov, and F.~Hutter, ``A downsampled variant of
  imagenet as an alternative to the cifar datasets,'' \emph{arXiv preprint
  arXiv:1707.08819}, 2017.

\bibitem{klein2017fast}
A.~Klein, S.~Falkner, S.~Bartels, P.~Hennig, and F.~Hutter, ``Fast bayesian
  optimization of machine learning hyperparameters on large datasets,'' in
  \emph{Artificial intelligence and statistics}.\hskip 1em plus 0.5em minus
  0.4em\relax PMLR, 2017, pp. 528--536.

\bibitem{9354953}
Y.~Xu, L.~Xie, W.~Dai, X.~Zhang, X.~Chen, G.-J. Qi, H.~Xiong, and Q.~Tian,
  ``Partially-connected neural architecture search for reduced computational
  redundancy,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, vol.~43, no.~9, pp. 2953--2970, 2021.

\bibitem{moser2022less}
B.~Moser, F.~Raue, J.~Hees, and A.~Dengel, ``Less is more: Proxy datasets in
  nas approaches,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 1953--1961.

\bibitem{liu2018darts}
H.~Liu, K.~Simonyan, and Y.~Yang, ``Darts: Differentiable architecture
  search,'' in \emph{International Conference on Learning Representations},
  2018.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in \emph{European conference on computer vision}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2014, pp. 740--755.

\bibitem{yang2020cars}
Z.~Yang, Y.~Wang, X.~Chen, B.~Shi, C.~Xu, C.~Xu, Q.~Tian, and C.~Xu, ``Cars:
  Continuous evolution for efficient neural architecture search,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2020, pp. 1829--1838.

\bibitem{o2021evolutionary}
D.~O’Neill, B.~Xue, and M.~Zhang, ``Evolutionary neural architecture search
  for high-dimensional skip-connection structures on densenet style networks,''
  \emph{IEEE Transactions on Evolutionary Computation}, vol.~25, no.~6, pp.
  1118--1132, 2021.

\bibitem{pham2018efficient}
H.~Pham, M.~Guan, B.~Zoph, Q.~Le, and J.~Dean, ``Efficient neural architecture
  search via parameters sharing,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 4095--4104.

\bibitem{luo2018neural}
R.~Luo, F.~Tian, T.~Qin, E.~Chen, and T.-Y. Liu, ``Neural architecture
  optimization,'' \emph{Advances in neural information processing systems},
  vol.~31, 2018.

\bibitem{bender2018understanding}
G.~Bender, P.-J. Kindermans, B.~Zoph, V.~Vasudevan, and Q.~Le, ``Understanding
  and simplifying one-shot architecture search,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2018, pp. 550--559.

\bibitem{zhang2020efficient}
H.~Zhang, Y.~Jin, R.~Cheng, and K.~Hao, ``Efficient evolutionary search of
  attention convolutional networks via sampled training and node inheritance,''
  \emph{IEEE Transactions on Evolutionary Computation}, vol.~25, no.~2, pp.
  371--385, 2020.

\bibitem{benyahia2019overcoming}
Y.~Benyahia, K.~Yu, K.~B. Smires, M.~Jaggi, A.~C. Davison, M.~Salzmann, and
  C.~Musat, ``Overcoming multi-model forgetting,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2019, pp. 594--603.

\bibitem{chu2021fairnas}
X.~Chu, B.~Zhang, and R.~Xu, ``Fairnas: Rethinking evaluation fairness of
  weight sharing neural architecture search,'' in \emph{Proceedings of the
  IEEE/CVF International Conference on Computer Vision}, 2021, pp.
  12\,239--12\,248.

\bibitem{ding2021bnas}
Z.~Ding, Y.~Chen, N.~Li, D.~Zhao, Z.~Sun, and C.~L.~P. Chen, ``Bnas: Efficient
  neural architecture search using broad scalable architecture,'' \emph{IEEE
  Transactions on Neural Networks and Learning Systems}, vol.~33, no.~9, pp.
  5004--5018, 2022.

\bibitem{zhou2022close}
Z.~Zhou, X.~Ning, Y.~Cai, J.~Han, Y.~Deng, Y.~Dong, H.~Yang, and Y.~Wang,
  ``Close: Curriculum learning on the sharing extent towards better one-shot
  nas,'' \emph{arXiv preprint arXiv:2207.07868}, 2022.

\bibitem{chen2019progressive}
X.~Chen, L.~Xie, J.~Wu, and Q.~Tian, ``Progressive differentiable architecture
  search: Bridging the depth gap between search and evaluation,'' in
  \emph{Proceedings of the IEEE International Conference on Computer Vision},
  2019, pp. 1294--1303.

\bibitem{xie2018snas}
S.~Xie, H.~Zheng, C.~Liu, and L.~Lin, ``Snas: stochastic neural architecture
  search,'' in \emph{International Conference on Learning Representations},
  2018.

\bibitem{zhou2021exploiting}
Y.~Zhou, X.~Xie, and S.-Y. Kung, ``Exploiting operation importance for
  differentiable neural architecture search,'' \emph{IEEE Transactions on
  Neural Networks and Learning Systems}, 2021.

\bibitem{9525822}
H.~Wang, R.~Yang, D.~Huang, and Y.~Wang, ``idarts: Improving darts by node
  normalization and decorrelation discretization,'' \emph{IEEE Transactions on
  Neural Networks and Learning Systems}, pp. 1--13, 2021.

\bibitem{xu2019pc}
Y.~Xu, L.~Xie, X.~Zhang, X.~Chen, G.-J. Qi, Q.~Tian, and H.~Xiong, ``Pc-darts:
  Partial channel connections for memory-efficient architecture search,'' in
  \emph{International Conference on Learning Representations}, 2019.

\bibitem{zhou2021bayesian}
Z.~Zhou, T.~Li, Z.~Zhang, Z.~Zhao, C.~Sun, R.~Yan, and X.~Chen, ``Bayesian
  differentiable architecture search for efficient domain matching fault
  diagnosis,'' \emph{IEEE Transactions on Instrumentation and Measurement},
  vol.~70, pp. 1--11, 2021.

\bibitem{9488309}
H.~Tan, R.~Cheng, S.~Huang, C.~He, C.~Qiu, F.~Yang, and P.~Luo, ``Relativenas:
  Relative neural architecture search via slow-fast learning,'' \emph{IEEE
  Transactions on Neural Networks and Learning Systems}, pp. 1--15, 2021.

\bibitem{liang2021opanas}
T.~Liang, Y.~Wang, Z.~Tang, G.~Hu, and H.~Ling, ``Opanas: One-shot path
  aggregation network architecture search for object detection,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2021, pp. 10\,195--10\,203.

\bibitem{xiong2021mobiledets}
Y.~Xiong, H.~Liu, S.~Gupta, B.~Akin, G.~Bender, Y.~Wang, P.-J. Kindermans,
  M.~Tan, V.~Singh, and B.~Chen, ``Mobiledets: Searching for object detection
  architectures for mobile accelerators,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2021, pp. 3825--3834.

\bibitem{guo2020hit}
J.~Guo, K.~Han, Y.~Wang, C.~Zhang, Z.~Yang, H.~Wu, X.~Chen, and C.~Xu,
  ``Hit-detector: Hierarchical trinity architecture search for object
  detection,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2020, pp. 11\,405--11\,414.

\bibitem{ning2021evaluating}
X.~Ning, C.~Tang, W.~Li, Z.~Zhou, S.~Liang, H.~Yang, and Y.~Wang, ``Evaluating
  efficient performance estimators of neural architectures,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~34, pp. 12\,265--12\,277, 2021.

\bibitem{chen2015net2net}
T.~Chen, I.~Goodfellow, and J.~Shlens, ``Net2net: Accelerating learning via
  knowledge transfer,'' \emph{arXiv preprint arXiv:1511.05641}, 2015.

\bibitem{cai2017reinforcement}
H.~Cai, T.~Chen, W.~Zhang, Y.~Yu, and J.~Wang, ``Reinforcement learning for
  architecture search by network transformation,'' \emph{arXiv preprint
  arXiv:1707.04873}, vol.~4, 2017.

\bibitem{cai2018efficient}
------, ``Efficient architecture search by network transformation,'' in
  \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  vol.~32, no.~1, 2018.

\bibitem{jin2011surrogate}
Y.~Jin, ``Surrogate-assisted evolutionary computation: Recent advances and
  future challenges,'' \emph{Swarm and Evolutionary Computation}, vol.~1,
  no.~2, pp. 61--70, 2011.

\bibitem{jin2005comprehensive}
------, ``A comprehensive survey of fitness approximation in evolutionary
  computation,'' \emph{Soft computing}, vol.~9, no.~1, pp. 3--12, 2005.

\bibitem{tao2019application}
J.~Tao and G.~Sun, ``Application of deep learning based multi-fidelity
  surrogate model to robust aerodynamic design optimization,'' \emph{Aerospace
  Science and Technology}, vol.~92, pp. 722--737, 2019.

\bibitem{sun2018semi}
C.~Sun, Y.~Jin, and Y.~Tan, ``Semi-supervised learning assisted particle swarm
  optimization of computationally expensive problems,'' in \emph{Proceedings of
  the Genetic and Evolutionary Computation Conference}, 2018, pp. 45--52.

\bibitem{wang2021transfer}
X.~Wang, Y.~Jin, S.~Schmitt, and M.~Olhofer, ``Transfer learning based
  co-surrogate assisted evolutionary bi-objective optimization for objectives
  with non-uniform evaluation times,'' \emph{Evolutionary computation}, pp.
  1--27, 2021.

\bibitem{wang2016data}
H.~Wang, Y.~Jin, and J.~O. Jansen, ``Data-driven surrogate-assisted
  multiobjective evolutionary optimization of a trauma system,'' \emph{IEEE
  Transactions on Evolutionary Computation}, vol.~20, no.~6, pp. 939--952,
  2016.

\bibitem{jin2018data}
Y.~Jin, H.~Wang, T.~Chugh, D.~Guo, and K.~Miettinen, ``Data-driven evolutionary
  optimization: An overview and case studies,'' \emph{IEEE Transactions on
  Evolutionary Computation}, vol.~23, no.~3, pp. 442--458, 2018.

\bibitem{sun2021data}
C.~Sun, H.~Wang, and Y.~Jin, \emph{Data-Driven Evolutionary Optimization:
  Integrating Evolutionary Computation, Machine Learning and Data
  Science}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2021.

\bibitem{shahriari2015taking}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~De~Freitas, ``Taking the
  human out of the loop: A review of bayesian optimization,'' \emph{Proceedings
  of the IEEE}, vol. 104, no.~1, pp. 148--175, 2015.

\bibitem{snoek2012practical}
J.~Snoek, H.~Larochelle, and R.~P. Adams, ``Practical bayesian optimization of
  machine learning algorithms,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~25, 2012.

\bibitem{mockus1978application}
J.~Mockus, V.~Tiesis, and A.~Zilinskas, ``The application of bayesian methods
  for seeking the extremum,'' \emph{Towards global optimization}, vol.~2, no.
  117-129, p.~2, 1978.

\bibitem{srinivas2010gaussian}
N.~Srinivas, A.~Krause, S.~M. Kakade, and M.~Seeger, ``Gaussian process
  optimization in the bandit setting: No regret and experimental design,'' in
  \emph{Proceedings of the International Conference on Machine Learning}, 2010.

\bibitem{hennig2012entropy}
P.~Hennig and C.~J. Schuler, ``Entropy search for information-efficient global
  optimization.'' \emph{Journal of Machine Learning Research}, vol.~13, no.~6,
  2012.

\bibitem{jin2019auto}
H.~Jin, Q.~Song, and X.~Hu, ``Auto-keras: An efficient neural architecture
  search system,'' in \emph{Proceedings of the 25th ACM SIGKDD international
  conference on knowledge discovery \& data mining}, 2019, pp. 1946--1956.

\bibitem{kandasamy2018neural}
K.~Kandasamy, W.~Neiswanger, J.~Schneider, B.~Poczos, and E.~P. Xing, ``Neural
  architecture search with bayesian optimisation and optimal transport,'' in
  \emph{Advances in Neural Information Processing Systems}, vol.~31, 2018.

\bibitem{ru2020interpretable}
B.~Ru, X.~Wan, X.~Dong, and M.~Osborne, ``Interpretable neural architecture
  search via bayesian optimisation with weisfeiler-lehman kernels,''
  \emph{arXiv preprint arXiv:2006.07556}, 2020.

\bibitem{white2021bananas}
C.~White, W.~Neiswanger, and Y.~Savani, ``Bananas: Bayesian optimization with
  neural architectures for neural architecture search,'' in \emph{Proceedings
  of the AAAI Conference on Artificial Intelligence}, vol.~35, no.~12, 2021,
  pp. 10\,293--10\,301.

\bibitem{shi2020bridging}
H.~Shi, R.~Pi, H.~Xu, Z.~Li, J.~Kwok, and T.~Zhang, ``Bridging the gap between
  sample-based and one-shot neural architecture search with bonas,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, pp.
  1808--1819, 2020.

\bibitem{kipf2016semi}
T.~N. Kipf and M.~Welling, ``Semi-supervised classification with graph
  convolutional networks,'' \emph{arXiv preprint arXiv:1609.02907}, 2016.

\bibitem{ma2019deep}
L.~Ma, J.~Cui, and B.~Yang, ``Deep neural architecture search with deep graph
  bayesian optimization,'' in \emph{2019 IEEE/WIC/ACM International Conference
  on Web Intelligence (WI)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019,
  pp. 500--507.

\bibitem{zhou2019bayesnas}
H.~Zhou, M.~Yang, J.~Wang, and W.~Pan, ``Bayesnas: A bayesian approach for
  neural architecture search,'' in \emph{International conference on machine
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 7603--7613.

\bibitem{ru2020neural}
R.~Ru, P.~Esperanca, and F.~M. Carlucci, ``Neural architecture generator
  optimization,'' \emph{Advances in Neural Information Processing Systems},
  vol.~33, pp. 12\,057--12\,069, 2020.

\bibitem{li2020gp}
Z.~Li, T.~Xi, J.~Deng, G.~Zhang, S.~Wen, and R.~He, ``Gp-nas: Gaussian process
  based neural architecture search,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2020, pp.
  11\,933--11\,942.

\bibitem{trofimov2020multi}
I.~Trofimov, N.~Klyuchnikov, M.~Salnikov, A.~Filippov, and E.~Burnaev,
  ``Multi-fidelity neural architecture search with knowledge distillation,''
  \emph{arXiv preprint arXiv:2006.08341}, 2020.

\bibitem{wei2020npenas}
C.~Wei, C.~Niu, Y.~Tang, Y.~Wang, H.~Hu, and J.~Liang, ``Npenas: Neural
  predictor guided evolution for neural architecture search,'' \emph{arXiv
  preprint arXiv:2003.12857}, 2020.

\bibitem{cho2022b2ea}
H.~Cho, J.~Shin, and W.~Rhee, ``B2ea: An evolutionary algorithm assisted by two
  bayesian optimization modules for neural architecture search,'' \emph{arXiv
  preprint arXiv:2202.03005}, 2022.

\bibitem{white2020study}
C.~White, W.~Neiswanger, S.~Nolen, and Y.~Savani, ``A study on encodings for
  neural architecture search,'' \emph{Advances in Neural Information Processing
  Systems}, vol.~33, pp. 20\,309--20\,319, 2020.

\bibitem{real2019regularized}
E.~Real, A.~Aggarwal, Y.~Huang, and Q.~V. Le, ``Regularized evolution for image
  classifier architecture search,'' in \emph{Proceedings of the aaai conference
  on artificial intelligence}, vol.~33, no.~01, 2019, pp. 4780--4789.

\bibitem{liu2017hierarchical}
H.~Liu, K.~Simonyan, O.~Vinyals, C.~Fernando, and K.~Kavukcuoglu,
  ``Hierarchical representations for efficient architecture search,''
  \emph{arXiv preprint arXiv:1711.00436}, 2017.

\bibitem{zhu2021toward}
H.~Zhu and Y.~Jin, ``Toward real-time federated evolutionary neural
  architecture search,'' in \emph{Automated Design of Machine Learning and
  Search Algorithms}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2021,
  pp. 133--147.

\bibitem{liu2021survey}
Y.~Liu, Y.~Sun, B.~Xue, M.~Zhang, G.~G. Yen, and K.~C. Tan, ``A survey on
  evolutionary neural architecture search,'' \emph{IEEE Transactions on Neural
  Networks and Learning Systems}, 2021.

\bibitem{sun2019surrogate}
Y.~Sun, H.~Wang, B.~Xue, Y.~Jin, G.~G. Yen, and M.~Zhang, ``Surrogate-assisted
  evolutionary deep learning using an end-to-end random forest-based
  performance predictor,'' \emph{IEEE Transactions on Evolutionary
  Computation}, vol.~24, no.~2, pp. 350--364, 2019.

\bibitem{sun2021novel}
Y.~Sun, X.~Sun, Y.~Fang, G.~G. Yen, and Y.~Liu, ``A novel training protocol for
  performance predictors of evolutionary neural architecture search
  algorithms,'' \emph{IEEE Transactions on Evolutionary Computation}, vol.~25,
  no.~3, pp. 524--536, 2021.

\bibitem{domhan2015speeding}
T.~Domhan, J.~T. Springenberg, and F.~Hutter, ``Speeding up automatic
  hyperparameter optimization of deep neural networks by extrapolation of
  learning curves,'' in \emph{Twenty-fourth international joint conference on
  artificial intelligence}, 2015.

\bibitem{klein2016learning}
A.~Klein, S.~Falkner, J.~T. Springenberg, and F.~Hutter, ``Learning curve
  prediction with bayesian neural networks,'' in \emph{International Conference
  on Learning Representations}, 2016.

\bibitem{baker2017accelerating}
B.~Baker, O.~Gupta, R.~Raskar, and N.~Naik, ``Accelerating neural architecture
  search using performance prediction,'' \emph{arXiv preprint
  arXiv:1705.10823}, 2017.

\bibitem{rawal2018nodes}
A.~Rawal and R.~Miikkulainen, ``From nodes to networks: Evolving recurrent
  neural networks,'' \emph{arXiv preprint arXiv:1803.04439}, 2018.

\bibitem{deng2017peephole}
B.~Deng, J.~Yan, and D.~Lin, ``Peephole: Predicting network performance before
  training,'' \emph{arXiv preprint arXiv:1712.03351}, 2017.

\bibitem{greenwood2022surrogate}
B.~Greenwood and T.~McDonnell, ``Surrogate-assisted neuroevolution,'' in
  \emph{Proceedings of the Genetic and Evolutionary Computation Conference},
  2022, pp. 1048--1056.

\bibitem{ho1995random}
T.~K. Ho, ``Random decision forests,'' in \emph{Proceedings of 3rd
  international conference on document analysis and recognition}, vol.~1.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 1995, pp. 278--282.

\bibitem{sun2019completely}
Y.~Sun, B.~Xue, M.~Zhang, and G.~G. Yen, ``Completely automated cnn
  architecture design based on blocks,'' \emph{IEEE transactions on neural
  networks and learning systems}, vol.~31, no.~4, pp. 1242--1254, 2019.

\bibitem{xu2018powerful}
K.~Xu, W.~Hu, J.~Leskovec, and S.~Jegelka, ``How powerful are graph neural
  networks?'' \emph{arXiv preprint arXiv:1810.00826}, 2018.

\bibitem{ying2019bench}
C.~Ying, A.~Klein, E.~Christiansen, E.~Real, K.~Murphy, and F.~Hutter,
  ``Nas-bench-101: Towards reproducible neural architecture search,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2019, pp. 7105--7114.

\bibitem{dong2020bench}
X.~Dong and Y.~Yang, ``Nas-bench-201: Extending the scope of reproducible
  neural architecture search,'' \emph{arXiv preprint arXiv:2001.00326}, 2020.

\bibitem{wen2020neural}
W.~Wen, H.~Liu, Y.~Chen, H.~Li, G.~Bender, and P.-J. Kindermans, ``Neural
  predictor for neural architecture search,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  660--676.

\bibitem{peng2022pre}
Y.~Peng, A.~Song, V.~Ciesielski, H.~M. Fayek, and X.~Chang, ``Pre-nas:
  Predictor-assisted evolutionary neural architecture search,'' \emph{arXiv
  preprint arXiv:2204.12726}, 2022.

\bibitem{liu2022bi}
J.~Liu, R.~Cheng, and Y.~Jin, ``Bi-fidelity evolutionary multiobjective search
  for adversarially robust deep neural architectures,'' \emph{arXiv preprint
  arXiv:2207.05321}, 2022.

\bibitem{ying2022multi}
W.~Ying, K.~Yang, Y.~Wu, J.~Li, Z.~Zhou, and B.~Huang, ``Multi-objective
  evolutionary architecture search of u-net with diamond atrous convolution,''
  in \emph{International Symposium on Intelligence Computation and
  Applications}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp.
  31--40.

\bibitem{wu2020comprehensive}
Z.~Wu, S.~Pan, F.~Chen, G.~Long, C.~Zhang, and S.~Y. Philip, ``A comprehensive
  survey on graph neural networks,'' \emph{IEEE transactions on neural networks
  and learning systems}, vol.~32, no.~1, pp. 4--24, 2020.

\bibitem{lukasik2020neural}
J.~Lukasik, D.~Friede, H.~Stuckenschmidt, and M.~Keuper, ``Neural architecture
  performance prediction using graph neural networks,'' in \emph{DAGM German
  Conference on Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2020, pp. 188--201.

\bibitem{tang2020semi}
Y.~Tang, Y.~Wang, Y.~Xu, H.~Chen, B.~Shi, C.~Xu, C.~Xu, Q.~Tian, and C.~Xu, ``A
  semi-supervised assessor of neural architectures,'' in \emph{Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  2020, pp. 1810--1819.

\bibitem{ning2020generic}
X.~Ning, Y.~Zheng, T.~Zhao, Y.~Wang, and H.~Yang, ``A generic graph-based
  neural architecture encoding scheme for predictor-based nas,'' in
  \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 189--204.

\bibitem{kyriakides2022evolving}
G.~Kyriakides and K.~Margaritis, ``Evolving graph convolutional networks for
  neural architecture search,'' \emph{Neural Computing and Applications},
  vol.~34, no.~2, pp. 899--909, 2022.

\bibitem{xu2021renas}
Y.~Xu, Y.~Wang, K.~Han, Y.~Tang, S.~Jui, C.~Xu, and C.~Xu, ``Renas:
  Relativistic evaluation of neural architecture search,'' in \emph{Proceedings
  of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021,
  pp. 4411--4420.

\bibitem{benmeziane2022pareto}
H.~Benmeziane, S.~Niar, H.~Ouarnoughi, and K.~El~Maghraoui, ``Pareto rank
  surrogate model for hardware-aware neural architecture search,'' in
  \emph{2022 IEEE International Symposium on Performance Analysis of Systems
  and Software (ISPASS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022,
  pp. 267--276.

\bibitem{huang2022arch}
M.~Huang, Z.~Huang, C.~Li, X.~Chen, H.~Xu, Z.~Li, and X.~Liang, ``Arch-graph:
  Acyclic architecture relation predictor for task-transferable neural
  architecture search,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2022, pp. 11\,881--11\,891.

\bibitem{white2021powerful}
C.~White, A.~Zela, R.~Ru, Y.~Liu, and F.~Hutter, ``How powerful are performance
  predictors in neural architecture search?'' \emph{Advances in Neural
  Information Processing Systems}, vol.~34, 2021.

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas,
  ``Communication-efficient learning of deep networks from decentralized
  data,'' in \emph{Artificial intelligence and statistics}.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 2017, pp. 1273--1282.

\bibitem{yang2019federated}
Q.~Yang, Y.~Liu, T.~Chen, and Y.~Tong, ``Federated machine learning: Concept
  and applications,'' \emph{ACM Transactions on Intelligent Systems and
  Technology (TIST)}, vol.~10, no.~2, pp. 1--19, 2019.

\bibitem{zhu2021federated}
H.~Zhu, J.~Xu, S.~Liu, and Y.~Jin, ``Federated learning on non-iid data: A
  survey,'' \emph{Neurocomputing}, vol. 465, pp. 371--390, 2021.

\bibitem{zhu2021from}
H.~Zhu, H.~Zhang, and Y.~Jin, ``From federated learning to federated neural
  architecture search: a survey,'' \emph{Complex \& Intelligent Systems},
  vol.~7, no.~2, pp. 639--657, 2021.

\bibitem{he2020towards}
C.~He, M.~Annavaram, and S.~Avestimehr, ``Towards non-iid and invisible data
  with fednas: federated deep learning via neural architecture search,''
  \emph{arXiv preprint arXiv:2004.08546}, 2020.

\bibitem{liang2021self}
X.~Liang, Y.~Liu, J.~Luo, Y.~He, T.~Chen, and Q.~Yang, ``Self-supervised
  cross-silo federated neural architecture search,'' \emph{arXiv preprint
  arXiv:2101.11896}, 2021.

\bibitem{singh2020differentially}
I.~Singh, H.~Zhou, K.~Yang, M.~Ding, B.~Lin, and P.~Xie,
  ``Differentially-private federated neural architecture search,'' \emph{arXiv
  preprint arXiv:2006.10559}, 2020.

\bibitem{xu2020federated}
M.~Xu, Y.~Zhao, K.~Bian, G.~Huang, Q.~Mei, and X.~Liu, ``Federated neural
  architecture search,'' \emph{arXiv preprint arXiv:2002.06352}, 2020.

\bibitem{liu2022federated}
X.~Liu, J.~Zhao, J.~Li, B.~Cao, and Z.~Lv, ``Federated neural architecture
  search for medical data security,'' \emph{IEEE Transactions on Industrial
  Informatics}, vol.~18, no.~8, pp. 5628--5636, 2022.

\bibitem{zhao2018federated}
Y.~Zhao, M.~Li, L.~Lai, N.~Suda, D.~Civin, and V.~Chandra, ``Federated learning
  with non-iid data,'' \emph{arXiv preprint arXiv:1806.00582}, 2018.

\bibitem{zhu2019deep}
L.~Zhu, Z.~Liu, and S.~Han, ``Deep leakage from gradients,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{dwork2014algorithmic}
C.~Dwork, A.~Roth \emph{et~al.}, ``The algorithmic foundations of differential
  privacy.'' \emph{Found. Trends Theor. Comput. Sci.}, vol.~9, no. 3-4, pp.
  211--407, 2014.

\bibitem{jin2008pareto}
Y.~Jin and B.~Sendhoff, ``Pareto-based multiobjective machine learning: An
  overview and case studies,'' \emph{IEEE Transactions on Systems, Man, and
  Cybernetics, Part C (Applications and Reviews)}, vol.~38, no.~3, pp.
  397--415, 2008.

\bibitem{dong2018dpp}
J.-D. Dong, A.-C. Cheng, D.-C. Juan, W.~Wei, and M.~Sun, ``Dpp-net:
  Device-aware progressive search for pareto-optimal neural architectures,'' in
  \emph{Proceedings of the European Conference on Computer Vision (ECCV)},
  2018, pp. 517--531.

\bibitem{lu2020nsganetv2}
Z.~Lu, K.~Deb, E.~Goodman, W.~Banzhaf, and V.~N. Boddeti, ``Nsganetv2:
  Evolutionary multi-objective surrogate-assisted neural architecture search,''
  in \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 35--51.

\bibitem{lu2022surrogate}
Z.~Lu, R.~Cheng, S.~Huang, H.~Zhang, C.~Qiu, and F.~Yang, ``Surrogate-assisted
  multi-objective neural architecture search for real-time semantic
  segmentation,'' \emph{arXiv preprint arXiv:2208.06820}, 2022.

\bibitem{liu2018hierarchical}
H.~Liu, K.~Simonyan, O.~Vinyals, C.~Fernando, and K.~Kavukcuoglu,
  ``Hierarchical representations for efficient architecture search,'' in
  \emph{International Conference on Learning Representations}, 2018.

\bibitem{chen2022mfenas}
L.~Chen and H.~Xu, ``Mfenas: multifactorial evolution for neural architecture
  search,'' in \emph{Proceedings of the Genetic and Evolutionary Computation
  Conference Companion}, 2022, pp. 631--634.

\bibitem{liu2018progressive}
C.~Liu, B.~Zoph, M.~Neumann, J.~Shlens, W.~Hua, L.-J. Li, L.~Fei-Fei,
  A.~Yuille, J.~Huang, and K.~Murphy, ``Progressive neural architecture
  search,'' in \emph{Proceedings of the European conference on computer vision
  (ECCV)}, 2018, pp. 19--34.

\bibitem{9432795}
Y.~Zhou, X.~Xie, and S.-Y. Kung, ``Exploiting operation importance for
  differentiable neural architecture search,'' \emph{IEEE Transactions on
  Neural Networks and Learning Systems}, pp. 1--14, 2021.

\bibitem{9447766}
Y.~Chen, R.~Gao, F.~Liu, and D.~Zhao, ``Modulenet: Knowledge-inherited neural
  architecture search,'' \emph{IEEE Transactions on Cybernetics}, pp. 1--11,
  2021.

\bibitem{9392299}
Z.~Ding, Y.~Chen, N.~Li, D.~Zhao, Z.~Sun, and C.~L.~P. Chen, ``Bnas: Efficient
  neural architecture search using broad scalable architecture,'' \emph{IEEE
  Transactions on Neural Networks and Learning Systems}, vol.~33, no.~9, pp.
  5004--5018, 2022.

\bibitem{dong2020searching}
X.~Dong and Y.~Yang, ``Searching for a robust neural architecture in four gpu
  hours,'' in \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020.

\bibitem{9247292}
M.~Zhang, H.~Li, S.~Pan, X.~Chang, C.~Zhou, Z.~Ge, and S.~Su, ``One-shot neural
  architecture search: Maximising diversity to overcome catastrophic
  forgetting,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, vol.~43, no.~9, pp. 2921--2935, 2021.

\bibitem{guo2021towards}
Y.~Guo, Y.~Zheng, M.~Tan, Q.~Chen, Z.~Li, J.~Chen, P.~Zhao, and J.~Huang,
  ``Towards accurate and compact architectures via neural architecture
  transformer,'' \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2021.

\bibitem{elsken2017simple}
T.~Elsken, J.-H. Metzen, and F.~Hutter, ``Simple and efficient architecture
  search for convolutional neural networks,'' \emph{arXiv preprint
  arXiv:1711.04528}, 2017.

\bibitem{bonawitz2016practical}
K.~Bonawitz, V.~Ivanov, B.~Kreuter, A.~Marcedone, H.~B. McMahan, S.~Patel,
  D.~Ramage, A.~Segal, and K.~Seth, ``Practical secure aggregation for
  federated learning on user-held data,'' \emph{arXiv preprint
  arXiv:1611.04482}, 2016.

\bibitem{acar2018survey}
A.~Acar, H.~Aksu, A.~S. Uluagac, and M.~Conti, ``A survey on homomorphic
  encryption schemes: Theory and implementation,'' \emph{ACM Computing Surveys
  (Csur)}, vol.~51, no.~4, pp. 1--35, 2018.

\bibitem{sun2022gibbon}
H.~Sun, C.~Wang, Z.~Zhu, X.~Ning, G.~Dai, H.~Yang, and Y.~Wang, ``Gibbon:
  efficient co-exploration of nn model and processing-in-memory architecture,''
  in \emph{2022 Design, Automation \& Test in Europe Conference \& Exhibition
  (DATE)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 867--872.

\end{thebibliography}
