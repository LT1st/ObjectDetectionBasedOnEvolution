{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About the dataset\nThis dataset was downloaded from NEU Metal Surface Defects Databse which contains six kinds of typical surface defects of the hot-rolled steel strip are collected, i.e., rolled-in scale (RS), patches (Pa), crazing (Cr), pitted surface (PS), inclusion (In) and scratches (Sc). The database includes 1,800 grayscale images: 300 samples each of six different kinds of typical surface defects.\n\nBut for this analysis, the dataset divided into 3 directories. The training directory contains 276 images of each class from the 300 images. The rest 24 images of each class also divided into tests and valid datasets.\n\nI don't know for sure about the dataset sharing as it's not my own data that's why I kept it private.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:28:54.173928Z","iopub.execute_input":"2023-04-13T01:28:54.174306Z","iopub.status.idle":"2023-04-13T01:28:54.180129Z","shell.execute_reply.started":"2023-04-13T01:28:54.174263Z","shell.execute_reply":"2023-04-13T01:28:54.178690Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/train'\nval_dir = '/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/valid'\ntest_dir='/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/test'\nprint(\"Path Direcorty: \",os.listdir(\"/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data\"))\nprint(\"Train Direcorty: \",os.listdir(\"/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/train\"))\nprint(\"Test Direcorty: \",os.listdir(\"/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/test\"))\nprint(\"Validation Direcorty: \",os.listdir(\"/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/valid\"))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:28:54.191662Z","iopub.execute_input":"2023-04-13T01:28:54.192071Z","iopub.status.idle":"2023-04-13T01:28:54.226999Z","shell.execute_reply.started":"2023-04-13T01:28:54.192035Z","shell.execute_reply":"2023-04-13T01:28:54.225949Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Path Direcorty:  ['Thumbs.db', 'valid', 'test', 'train']\nTrain Direcorty:  ['Inclusion', 'Rolled', 'Pitted', 'Scratches', 'Patches', 'Crazing']\nTest Direcorty:  ['Inclusion', 'Rolled', 'Pitted', 'Scratches', 'Patches', 'Crazing']\nValidation Direcorty:  ['Inclusion', 'Rolled', 'Pitted', 'Scratches', 'Patches', 'Crazing']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Here, you can see the dataset distribution for 'Inclusion' surface defect. Rest of the dataset also follow the same distribution","metadata":{}},{"cell_type":"code","source":"print(\"Training Inclusion data:\",len(os.listdir(train_dir+'/'+'Inclusion')))\n\nprint(\"Testing Inclusion data:\",len(os.listdir(test_dir+'/'+'Inclusion')))\n\nprint(\"Validation Inclusion data:\",len(os.listdir(val_dir+'/'+'Inclusion')))","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:28:54.229057Z","iopub.execute_input":"2023-04-13T01:28:54.229367Z","iopub.status.idle":"2023-04-13T01:28:54.337143Z","shell.execute_reply.started":"2023-04-13T01:28:54.229336Z","shell.execute_reply":"2023-04-13T01:28:54.335963Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Training Inclusion data: 276\nTesting Inclusion data: 12\nValidation Inclusion data: 12\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:28:54.338557Z","iopub.execute_input":"2023-04-13T01:28:54.338834Z","iopub.status.idle":"2023-04-13T01:29:01.372436Z","shell.execute_reply.started":"2023-04-13T01:28:54.338805Z","shell.execute_reply":"2023-04-13T01:29:01.371460Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing the data","metadata":{}},{"cell_type":"code","source":"# All images will be rescaled by 1./255\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Flow training images in batches of 10 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(200, 200),\n        batch_size=10,\n        class_mode='categorical')\n\n# Flow validation images in batches of 10 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        val_dir,\n        target_size=(200, 200),\n        batch_size=10,\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:29:01.377038Z","iopub.execute_input":"2023-04-13T01:29:01.379082Z","iopub.status.idle":"2023-04-13T01:29:02.002195Z","shell.execute_reply.started":"2023-04-13T01:29:01.379035Z","shell.execute_reply":"2023-04-13T01:29:02.000993Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 1656 images belonging to 6 classes.\nFound 72 images belonging to 6 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Stop training the model at 98% traning accuracy","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy') > 0.98 ):\n            print(\"\\nReached 98% accuracy so cancelling training!\")\n            self.model.stop_training = True ","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:29:02.007586Z","iopub.execute_input":"2023-04-13T01:29:02.010018Z","iopub.status.idle":"2023-04-13T01:29:02.017876Z","shell.execute_reply.started":"2023-04-13T01:29:02.009962Z","shell.execute_reply":"2023-04-13T01:29:02.016766Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (2,2), activation='relu', input_shape=(200, 200, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:29:02.021913Z","iopub.execute_input":"2023-04-13T01:29:02.024909Z","iopub.status.idle":"2023-04-13T01:29:02.665546Z","shell.execute_reply.started":"2023-04-13T01:29:02.024851Z","shell.execute_reply":"2023-04-13T01:29:02.664695Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 199, 199, 32)      416       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 98, 98, 64)        8256      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 48, 48, 128)       32896     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 24, 24, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 73728)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               18874624  \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 6)                 1542      \n=================================================================\nTotal params: 18,917,734\nTrainable params: 18,917,734\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\nprint('Compiled!')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:29:02.669741Z","iopub.execute_input":"2023-04-13T01:29:02.671829Z","iopub.status.idle":"2023-04-13T01:29:02.692489Z","shell.execute_reply.started":"2023-04-13T01:29:02.671780Z","shell.execute_reply":"2023-04-13T01:29:02.691318Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Compiled!\n","output_type":"stream"}]},{"cell_type":"code","source":"callbacks = myCallback()\nhistory = model.fit(train_generator,\n        batch_size = 32,\n        epochs=20,\n        validation_data=validation_generator,\n        callbacks=[callbacks],\n        verbose=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T01:29:02.697148Z","iopub.execute_input":"2023-04-13T01:29:02.699267Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n 52/166 [========>.....................] - ETA: 2:16 - loss: 2.2005 - accuracy: 0.2135","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.figure(1)  \n# summarize history for accuracy  \nplt.subplot(211)  \nplt.plot(history.history['accuracy'])  \nplt.plot(history.history['val_accuracy'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \n   \n # summarize history for loss  \n   \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Result visualization","metadata":{}},{"cell_type":"code","source":"# First, we are going to load the file names and their respective target labels into numpy array! \nfrom sklearn.datasets import load_files\nimport numpy as np\n\ntest_dir = '/kaggle/input/neu-metal-surface-defects-data/NEU Metal Surface Defects Data/test'\n\ndef load_dataset(path):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files,targets,target_labels\n    \nx_test, y_test,target_labels = load_dataset(test_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_of_classes = len(np.unique(y_test))\nno_of_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils\ny_test = np_utils.to_categorical(y_test,no_of_classes)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We just have the file names in the x set. Let's load the images and convert them into array.\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        images_as_array.append(img_to_array(load_img(file)))\n    return images_as_array\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = x_test.astype('float32')/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's visualize test prediction.\n\ny_pred = model.predict(x_test)\n\n# plot a raandom sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}