[2023-05-02 11:20:14.393372]-Used GPU#0, worker name:Process-171[20084]
[2023-05-02 11:21:27.515380]-Train-Epoch:  1,  Loss: 1.482, Acc:0.384
[2023-05-02 11:21:39.360289]-Validate-Loss:1.436, Acc:0.667
[2023-05-02 11:22:44.769096]-Train-Epoch:  2,  Loss: 1.091, Acc:0.571
[2023-05-02 11:22:55.618758]-Validate-Loss:0.987, Acc:0.727
[2023-05-02 11:24:01.301255]-Train-Epoch:  3,  Loss: 1.008, Acc:0.611
[2023-05-02 11:24:12.190929]-Validate-Loss:1.203, Acc:0.677
[2023-05-02 11:25:17.654723]-Train-Epoch:  4,  Loss: 0.984, Acc:0.612
[2023-05-02 11:25:28.425433]-Validate-Loss:0.867, Acc:0.769
[2023-05-02 11:26:33.970204]-Train-Epoch:  5,  Loss: 0.877, Acc:0.655
[2023-05-02 11:26:44.991055]-Validate-Loss:0.896, Acc:0.762
[2023-05-02 11:27:50.591214]-Train-Epoch:  6,  Loss: 0.749, Acc:0.709
[2023-05-02 11:28:01.522781]-Validate-Loss:0.754, Acc:0.742
[2023-05-02 11:29:07.092153]-Train-Epoch:  7,  Loss: 0.678, Acc:0.752
[2023-05-02 11:29:17.977694]-Validate-Loss:0.672, Acc:0.792
[2023-05-02 11:30:23.623132]-Train-Epoch:  8,  Loss: 0.633, Acc:0.760
[2023-05-02 11:30:34.571916]-Validate-Loss:0.597, Acc:0.781
[2023-05-02 11:31:40.210513]-Train-Epoch:  9,  Loss: 0.534, Acc:0.802
[2023-05-02 11:31:51.200192]-Validate-Loss:0.575, Acc:0.810
[2023-05-02 11:32:56.733935]-Train-Epoch: 10,  Loss: 0.519, Acc:0.823
[2023-05-02 11:33:07.675687]-Validate-Loss:0.255, Acc:0.921
[2023-05-02 11:34:13.267417]-Train-Epoch: 11,  Loss: 0.449, Acc:0.846
[2023-05-02 11:34:24.109882]-Validate-Loss:0.551, Acc:0.896
[2023-05-02 11:35:29.713927]-Train-Epoch: 12,  Loss: 0.462, Acc:0.841
[2023-05-02 11:35:40.637225]-Validate-Loss:0.384, Acc:0.858
[2023-05-02 11:36:46.154439]-Train-Epoch: 13,  Loss: 0.386, Acc:0.861
[2023-05-02 11:36:57.011011]-Validate-Loss:0.349, Acc:0.885
[2023-05-02 11:38:02.461527]-Train-Epoch: 14,  Loss: 0.397, Acc:0.873
[2023-05-02 11:38:13.334072]-Validate-Loss:0.946, Acc:0.838
[2023-05-02 11:39:18.684559]-Train-Epoch: 15,  Loss: 0.329, Acc:0.880
[2023-05-02 11:39:29.512984]-Validate-Loss:0.223, Acc:0.935
[2023-05-02 11:40:34.911012]-Train-Epoch: 16,  Loss: 0.326, Acc:0.881
[2023-05-02 11:40:45.687631]-Validate-Loss:1.300, Acc:0.844
[2023-05-02 11:41:51.065707]-Train-Epoch: 17,  Loss: 0.287, Acc:0.905
[2023-05-02 11:42:01.906298]-Validate-Loss:0.532, Acc:0.890
[2023-05-02 11:43:07.383994]-Train-Epoch: 18,  Loss: 0.262, Acc:0.912
[2023-05-02 11:43:18.229748]-Validate-Loss:0.970, Acc:0.883
[2023-05-02 11:44:23.664466]-Train-Epoch: 19,  Loss: 0.271, Acc:0.910
[2023-05-02 11:44:34.571525]-Validate-Loss:0.376, Acc:0.910
[2023-05-02 11:45:40.050144]-Train-Epoch: 20,  Loss: 0.251, Acc:0.916
[2023-05-02 11:45:50.914041]-Validate-Loss:0.473, Acc:0.902
[2023-05-02 11:46:56.396506]-Train-Epoch: 21,  Loss: 0.245, Acc:0.910
[2023-05-02 11:47:07.284184]-Validate-Loss:0.200, Acc:0.933
[2023-05-02 11:48:12.670221]-Train-Epoch: 22,  Loss: 0.207, Acc:0.915
[2023-05-02 11:48:23.515370]-Validate-Loss:0.321, Acc:0.923
[2023-05-02 11:49:28.910693]-Train-Epoch: 23,  Loss: 0.208, Acc:0.928
[2023-05-02 11:49:39.707462]-Validate-Loss:0.597, Acc:0.890
[2023-05-02 11:50:45.080409]-Train-Epoch: 24,  Loss: 0.213, Acc:0.932
[2023-05-02 11:50:55.889867]-Validate-Loss:0.106, Acc:0.963
[2023-05-02 11:52:01.263386]-Train-Epoch: 25,  Loss: 0.207, Acc:0.930
[2023-05-02 11:52:12.069991]-Validate-Loss:0.361, Acc:0.913
[2023-05-02 11:53:17.409349]-Train-Epoch: 26,  Loss: 0.196, Acc:0.925
[2023-05-02 11:53:28.266893]-Validate-Loss:0.207, Acc:0.940
[2023-05-02 11:54:33.716779]-Train-Epoch: 27,  Loss: 0.177, Acc:0.942
[2023-05-02 11:54:44.556113]-Validate-Loss:0.294, Acc:0.927
[2023-05-02 11:55:49.990096]-Train-Epoch: 28,  Loss: 0.204, Acc:0.930
[2023-05-02 11:56:00.820858]-Validate-Loss:0.244, Acc:0.921
[2023-05-02 11:57:06.297865]-Train-Epoch: 29,  Loss: 0.167, Acc:0.943
[2023-05-02 11:57:17.172018]-Validate-Loss:0.116, Acc:0.962
[2023-05-02 11:58:22.536111]-Train-Epoch: 30,  Loss: 0.153, Acc:0.946
[2023-05-02 11:58:33.331780]-Validate-Loss:0.255, Acc:0.950
[2023-05-02 11:58:33.338776]-Finished-Acc:0.963
