[2023-05-01 17:59:03.660417]-Used GPU#1, worker name:Process-77[10084]
[2023-05-01 17:59:22.841948]-Train-Epoch:  1,  Loss: 2.212, Acc:0.365
[2023-05-01 17:59:27.508042]-Validate-Loss:1.819, Acc:0.406
[2023-05-01 17:59:41.914059]-Train-Epoch:  2,  Loss: 1.454, Acc:0.525
[2023-05-01 17:59:45.807629]-Validate-Loss:4.058, Acc:0.392
[2023-05-01 18:00:00.148178]-Train-Epoch:  3,  Loss: 1.382, Acc:0.544
[2023-05-01 18:00:04.065275]-Validate-Loss:1.715, Acc:0.548
[2023-05-01 18:00:18.423944]-Train-Epoch:  4,  Loss: 1.079, Acc:0.615
[2023-05-01 18:00:22.315766]-Validate-Loss:2.597, Acc:0.671
[2023-05-01 18:00:36.875567]-Train-Epoch:  5,  Loss: 0.952, Acc:0.672
[2023-05-01 18:00:40.708648]-Validate-Loss:1.562, Acc:0.710
[2023-05-01 18:00:55.038281]-Train-Epoch:  6,  Loss: 0.862, Acc:0.695
[2023-05-01 18:00:58.881929]-Validate-Loss:7.652, Acc:0.531
[2023-05-01 18:01:13.278960]-Train-Epoch:  7,  Loss: 0.816, Acc:0.718
[2023-05-01 18:01:17.146312]-Validate-Loss:1.139, Acc:0.735
[2023-05-01 18:01:31.686821]-Train-Epoch:  8,  Loss: 0.720, Acc:0.756
[2023-05-01 18:01:35.645220]-Validate-Loss:1.328, Acc:0.729
[2023-05-01 18:01:50.011756]-Train-Epoch:  9,  Loss: 0.678, Acc:0.766
[2023-05-01 18:01:53.809499]-Validate-Loss:0.541, Acc:0.806
[2023-05-01 18:02:08.209198]-Train-Epoch: 10,  Loss: 0.654, Acc:0.767
[2023-05-01 18:02:11.996345]-Validate-Loss:1.002, Acc:0.752
[2023-05-01 18:02:26.359827]-Train-Epoch: 11,  Loss: 0.556, Acc:0.792
[2023-05-01 18:02:30.183622]-Validate-Loss:0.567, Acc:0.788
[2023-05-01 18:02:44.513366]-Train-Epoch: 12,  Loss: 0.521, Acc:0.814
[2023-05-01 18:02:48.425830]-Validate-Loss:0.560, Acc:0.777
[2023-05-01 18:03:02.725587]-Train-Epoch: 13,  Loss: 0.520, Acc:0.824
[2023-05-01 18:03:06.643558]-Validate-Loss:0.933, Acc:0.794
[2023-05-01 18:03:21.124335]-Train-Epoch: 14,  Loss: 0.514, Acc:0.809
[2023-05-01 18:03:24.962515]-Validate-Loss:0.720, Acc:0.777
[2023-05-01 18:03:39.339829]-Train-Epoch: 15,  Loss: 0.483, Acc:0.834
[2023-05-01 18:03:43.214290]-Validate-Loss:0.425, Acc:0.863
[2023-05-01 18:03:57.719781]-Train-Epoch: 16,  Loss: 0.425, Acc:0.846
[2023-05-01 18:04:01.542844]-Validate-Loss:0.501, Acc:0.835
[2023-05-01 18:04:15.936265]-Train-Epoch: 17,  Loss: 0.405, Acc:0.861
[2023-05-01 18:04:19.782977]-Validate-Loss:0.405, Acc:0.850
[2023-05-01 18:04:34.147603]-Train-Epoch: 18,  Loss: 0.390, Acc:0.865
[2023-05-01 18:04:37.967727]-Validate-Loss:0.391, Acc:0.858
[2023-05-01 18:04:52.315843]-Train-Epoch: 19,  Loss: 0.286, Acc:0.905
[2023-05-01 18:04:56.168359]-Validate-Loss:0.556, Acc:0.862
[2023-05-01 18:05:10.477775]-Train-Epoch: 20,  Loss: 0.292, Acc:0.902
[2023-05-01 18:05:14.366839]-Validate-Loss:0.221, Acc:0.929
[2023-05-01 18:05:28.914086]-Train-Epoch: 21,  Loss: 0.240, Acc:0.910
[2023-05-01 18:05:32.734772]-Validate-Loss:0.463, Acc:0.879
[2023-05-01 18:05:47.138612]-Train-Epoch: 22,  Loss: 0.317, Acc:0.891
[2023-05-01 18:05:50.923704]-Validate-Loss:0.318, Acc:0.912
[2023-05-01 18:06:05.338029]-Train-Epoch: 23,  Loss: 0.262, Acc:0.905
[2023-05-01 18:06:09.154330]-Validate-Loss:0.283, Acc:0.925
[2023-05-01 18:06:23.500821]-Train-Epoch: 24,  Loss: 0.258, Acc:0.905
[2023-05-01 18:06:27.344222]-Validate-Loss:0.704, Acc:0.883
[2023-05-01 18:06:41.684923]-Train-Epoch: 25,  Loss: 0.303, Acc:0.899
[2023-05-01 18:06:45.502987]-Validate-Loss:0.191, Acc:0.927
[2023-05-01 18:06:59.920709]-Train-Epoch: 26,  Loss: 0.271, Acc:0.914
[2023-05-01 18:07:03.847409]-Validate-Loss:0.518, Acc:0.881
[2023-05-01 18:07:18.347148]-Train-Epoch: 27,  Loss: 0.274, Acc:0.901
[2023-05-01 18:07:22.259841]-Validate-Loss:0.268, Acc:0.915
[2023-05-01 18:07:36.606916]-Train-Epoch: 28,  Loss: 0.224, Acc:0.918
[2023-05-01 18:07:40.432290]-Validate-Loss:0.345, Acc:0.917
[2023-05-01 18:07:54.875287]-Train-Epoch: 29,  Loss: 0.248, Acc:0.920
[2023-05-01 18:07:58.882115]-Validate-Loss:0.223, Acc:0.919
[2023-05-01 18:08:13.270776]-Train-Epoch: 30,  Loss: 0.229, Acc:0.923
[2023-05-01 18:08:17.086239]-Validate-Loss:0.251, Acc:0.937
[2023-05-01 18:08:17.092783]-Finished-Acc:0.937
