[2023-05-03 04:37:25.087092]-Used GPU#0, worker name:Process-268[9128]
[2023-05-03 04:37:59.167625]-Train-Epoch:  1,  Loss: 18.540, Acc:0.306
[2023-05-03 04:38:05.934307]-Validate-Loss:22.025, Acc:0.269
[2023-05-03 04:38:35.699959]-Train-Epoch:  2,  Loss: 3.324, Acc:0.438
[2023-05-03 04:38:41.257360]-Validate-Loss:2.135, Acc:0.423
[2023-05-03 04:39:10.978972]-Train-Epoch:  3,  Loss: 2.356, Acc:0.464
[2023-05-03 04:39:16.517922]-Validate-Loss:4.026, Acc:0.431
[2023-05-03 04:39:46.208913]-Train-Epoch:  4,  Loss: 1.820, Acc:0.534
[2023-05-03 04:39:51.749651]-Validate-Loss:1.891, Acc:0.523
[2023-05-03 04:40:21.461889]-Train-Epoch:  5,  Loss: 1.335, Acc:0.610
[2023-05-03 04:40:27.023980]-Validate-Loss:1.106, Acc:0.677
[2023-05-03 04:40:56.797853]-Train-Epoch:  6,  Loss: 1.152, Acc:0.652
[2023-05-03 04:41:02.308953]-Validate-Loss:0.779, Acc:0.723
[2023-05-03 04:41:32.043084]-Train-Epoch:  7,  Loss: 0.985, Acc:0.688
[2023-05-03 04:41:37.635699]-Validate-Loss:1.081, Acc:0.706
[2023-05-03 04:42:07.262774]-Train-Epoch:  8,  Loss: 0.813, Acc:0.740
[2023-05-03 04:42:12.799740]-Validate-Loss:0.587, Acc:0.856
[2023-05-03 04:42:42.633317]-Train-Epoch:  9,  Loss: 0.739, Acc:0.761
[2023-05-03 04:42:48.217157]-Validate-Loss:0.720, Acc:0.779
[2023-05-03 04:43:17.878974]-Train-Epoch: 10,  Loss: 0.771, Acc:0.764
[2023-05-03 04:43:23.468760]-Validate-Loss:0.796, Acc:0.746
[2023-05-03 04:43:53.425745]-Train-Epoch: 11,  Loss: 1.061, Acc:0.706
[2023-05-03 04:43:58.997552]-Validate-Loss:0.784, Acc:0.712
[2023-05-03 04:44:28.837244]-Train-Epoch: 12,  Loss: 0.710, Acc:0.774
[2023-05-03 04:44:34.421107]-Validate-Loss:0.523, Acc:0.812
[2023-05-03 04:45:04.374466]-Train-Epoch: 13,  Loss: 0.639, Acc:0.791
[2023-05-03 04:45:10.012124]-Validate-Loss:0.633, Acc:0.829
[2023-05-03 04:45:39.799296]-Train-Epoch: 14,  Loss: 0.552, Acc:0.826
[2023-05-03 04:45:45.413132]-Validate-Loss:0.764, Acc:0.754
[2023-05-03 04:46:15.546290]-Train-Epoch: 15,  Loss: 0.502, Acc:0.845
[2023-05-03 04:46:21.171682]-Validate-Loss:0.303, Acc:0.917
[2023-05-03 04:46:50.919576]-Train-Epoch: 16,  Loss: 0.479, Acc:0.848
[2023-05-03 04:46:56.489107]-Validate-Loss:0.193, Acc:0.927
[2023-05-03 04:47:26.168704]-Train-Epoch: 17,  Loss: 0.388, Acc:0.873
[2023-05-03 04:47:31.783088]-Validate-Loss:0.285, Acc:0.913
[2023-05-03 04:48:01.559556]-Train-Epoch: 18,  Loss: 0.385, Acc:0.875
[2023-05-03 04:48:07.137483]-Validate-Loss:0.385, Acc:0.871
[2023-05-03 04:48:36.982009]-Train-Epoch: 19,  Loss: 0.372, Acc:0.886
[2023-05-03 04:48:42.577462]-Validate-Loss:0.253, Acc:0.900
[2023-05-03 04:49:12.278116]-Train-Epoch: 20,  Loss: 0.387, Acc:0.871
[2023-05-03 04:49:17.918614]-Validate-Loss:0.198, Acc:0.938
[2023-05-03 04:49:47.688543]-Train-Epoch: 21,  Loss: 0.323, Acc:0.903
[2023-05-03 04:49:53.278172]-Validate-Loss:0.629, Acc:0.885
[2023-05-03 04:50:22.992847]-Train-Epoch: 22,  Loss: 0.290, Acc:0.915
[2023-05-03 04:50:28.490675]-Validate-Loss:0.445, Acc:0.900
[2023-05-03 04:50:58.204016]-Train-Epoch: 23,  Loss: 0.323, Acc:0.903
[2023-05-03 04:51:03.713856]-Validate-Loss:0.176, Acc:0.935
[2023-05-03 04:51:33.337262]-Train-Epoch: 24,  Loss: 0.261, Acc:0.923
[2023-05-03 04:51:38.827422]-Validate-Loss:0.476, Acc:0.883
[2023-05-03 04:52:08.648184]-Train-Epoch: 25,  Loss: 0.254, Acc:0.922
[2023-05-03 04:52:14.241796]-Validate-Loss:0.132, Acc:0.958
[2023-05-03 04:52:43.951105]-Train-Epoch: 26,  Loss: 0.266, Acc:0.920
[2023-05-03 04:52:49.416053]-Validate-Loss:0.158, Acc:0.946
[2023-05-03 04:53:19.201049]-Train-Epoch: 27,  Loss: 0.233, Acc:0.920
[2023-05-03 04:53:24.717412]-Validate-Loss:0.667, Acc:0.921
[2023-05-03 04:53:54.419541]-Train-Epoch: 28,  Loss: 0.208, Acc:0.926
[2023-05-03 04:53:59.949023]-Validate-Loss:0.184, Acc:0.946
[2023-05-03 04:54:29.544055]-Train-Epoch: 29,  Loss: 0.211, Acc:0.928
[2023-05-03 04:54:35.026159]-Validate-Loss:0.129, Acc:0.948
[2023-05-03 04:55:04.628012]-Train-Epoch: 30,  Loss: 0.215, Acc:0.924
[2023-05-03 04:55:10.176029]-Validate-Loss:0.554, Acc:0.940
[2023-05-03 04:55:10.182573]-Finished-Acc:0.958
