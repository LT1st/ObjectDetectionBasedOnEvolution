[2023-05-01 21:38:07.593293]-Used GPU#1, worker name:Process-100[13624]
[2023-05-01 21:38:27.632723]-Train-Epoch:  1,  Loss: 1.404, Acc:0.437
[2023-05-01 21:38:32.294331]-Validate-Loss:3.637, Acc:0.477
[2023-05-01 21:38:47.803211]-Train-Epoch:  2,  Loss: 1.013, Acc:0.605
[2023-05-01 21:38:51.686045]-Validate-Loss:4.295, Acc:0.398
[2023-05-01 21:39:07.162036]-Train-Epoch:  3,  Loss: 0.909, Acc:0.663
[2023-05-01 21:39:11.088030]-Validate-Loss:1.878, Acc:0.612
[2023-05-01 21:39:26.690615]-Train-Epoch:  4,  Loss: 0.790, Acc:0.710
[2023-05-01 21:39:30.666978]-Validate-Loss:3.234, Acc:0.546
[2023-05-01 21:39:46.231283]-Train-Epoch:  5,  Loss: 0.717, Acc:0.743
[2023-05-01 21:39:50.240395]-Validate-Loss:0.579, Acc:0.813
[2023-05-01 21:40:05.634467]-Train-Epoch:  6,  Loss: 0.627, Acc:0.778
[2023-05-01 21:40:09.559299]-Validate-Loss:0.478, Acc:0.833
[2023-05-01 21:40:24.818067]-Train-Epoch:  7,  Loss: 0.493, Acc:0.822
[2023-05-01 21:40:28.777572]-Validate-Loss:0.632, Acc:0.867
[2023-05-01 21:40:43.995352]-Train-Epoch:  8,  Loss: 0.507, Acc:0.829
[2023-05-01 21:40:47.978478]-Validate-Loss:0.618, Acc:0.871
[2023-05-01 21:41:03.284717]-Train-Epoch:  9,  Loss: 0.412, Acc:0.852
[2023-05-01 21:41:07.234762]-Validate-Loss:1.081, Acc:0.775
[2023-05-01 21:41:22.517233]-Train-Epoch: 10,  Loss: 0.361, Acc:0.887
[2023-05-01 21:41:26.374154]-Validate-Loss:0.923, Acc:0.883
[2023-05-01 21:41:41.669910]-Train-Epoch: 11,  Loss: 0.371, Acc:0.866
[2023-05-01 21:41:45.565007]-Validate-Loss:0.612, Acc:0.904
[2023-05-01 21:42:00.899031]-Train-Epoch: 12,  Loss: 0.355, Acc:0.880
[2023-05-01 21:42:04.815301]-Validate-Loss:0.942, Acc:0.858
[2023-05-01 21:42:20.104819]-Train-Epoch: 13,  Loss: 0.301, Acc:0.896
[2023-05-01 21:42:23.960033]-Validate-Loss:2.556, Acc:0.704
[2023-05-01 21:42:39.223676]-Train-Epoch: 14,  Loss: 0.321, Acc:0.888
[2023-05-01 21:42:43.149820]-Validate-Loss:0.492, Acc:0.925
[2023-05-01 21:42:58.463103]-Train-Epoch: 15,  Loss: 0.309, Acc:0.887
[2023-05-01 21:43:02.376735]-Validate-Loss:0.966, Acc:0.871
[2023-05-01 21:43:17.662992]-Train-Epoch: 16,  Loss: 0.280, Acc:0.904
[2023-05-01 21:43:21.532074]-Validate-Loss:0.639, Acc:0.915
[2023-05-01 21:43:36.820336]-Train-Epoch: 17,  Loss: 0.221, Acc:0.930
[2023-05-01 21:43:40.755257]-Validate-Loss:0.447, Acc:0.881
[2023-05-01 21:43:56.066649]-Train-Epoch: 18,  Loss: 0.192, Acc:0.938
[2023-05-01 21:43:59.933682]-Validate-Loss:0.170, Acc:0.938
[2023-05-01 21:44:15.193349]-Train-Epoch: 19,  Loss: 0.219, Acc:0.921
[2023-05-01 21:44:19.138310]-Validate-Loss:0.761, Acc:0.869
[2023-05-01 21:44:34.434607]-Train-Epoch: 20,  Loss: 0.223, Acc:0.923
[2023-05-01 21:44:38.351132]-Validate-Loss:0.765, Acc:0.883
[2023-05-01 21:44:53.657598]-Train-Epoch: 21,  Loss: 0.190, Acc:0.932
[2023-05-01 21:44:57.495969]-Validate-Loss:1.319, Acc:0.860
[2023-05-01 21:45:12.684826]-Train-Epoch: 22,  Loss: 0.177, Acc:0.941
[2023-05-01 21:45:16.559619]-Validate-Loss:0.539, Acc:0.906
[2023-05-01 21:45:31.822419]-Train-Epoch: 23,  Loss: 0.206, Acc:0.926
[2023-05-01 21:45:35.734796]-Validate-Loss:0.518, Acc:0.919
[2023-05-01 21:45:51.052692]-Train-Epoch: 24,  Loss: 0.157, Acc:0.947
[2023-05-01 21:45:55.002598]-Validate-Loss:2.143, Acc:0.723
[2023-05-01 21:46:10.223200]-Train-Epoch: 25,  Loss: 0.168, Acc:0.945
[2023-05-01 21:46:14.126681]-Validate-Loss:0.741, Acc:0.896
[2023-05-01 21:46:29.427644]-Train-Epoch: 26,  Loss: 0.158, Acc:0.949
[2023-05-01 21:46:33.319654]-Validate-Loss:0.691, Acc:0.892
[2023-05-01 21:46:48.587781]-Train-Epoch: 27,  Loss: 0.165, Acc:0.945
[2023-05-01 21:46:52.459850]-Validate-Loss:0.335, Acc:0.902
[2023-05-01 21:47:07.723164]-Train-Epoch: 28,  Loss: 0.156, Acc:0.952
[2023-05-01 21:47:11.687705]-Validate-Loss:2.599, Acc:0.827
[2023-05-01 21:47:26.993294]-Train-Epoch: 29,  Loss: 0.185, Acc:0.937
[2023-05-01 21:47:30.899830]-Validate-Loss:0.936, Acc:0.910
[2023-05-01 21:47:46.203473]-Train-Epoch: 30,  Loss: 0.162, Acc:0.945
[2023-05-01 21:47:50.112526]-Validate-Loss:0.860, Acc:0.919
[2023-05-01 21:47:50.119514]-Finished-Acc:0.938
