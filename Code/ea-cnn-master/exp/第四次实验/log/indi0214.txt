[2023-05-01 17:32:24.666863]-Used GPU#1, worker name:Process-72[2736]
[2023-05-01 17:32:41.877601]-Train-Epoch:  1,  Loss: 1.430, Acc:0.430
[2023-05-01 17:32:46.236042]-Validate-Loss:1.836, Acc:0.488
[2023-05-01 17:32:59.249901]-Train-Epoch:  2,  Loss: 1.035, Acc:0.626
[2023-05-01 17:33:03.003120]-Validate-Loss:0.850, Acc:0.737
[2023-05-01 17:33:15.959319]-Train-Epoch:  3,  Loss: 0.849, Acc:0.697
[2023-05-01 17:33:19.573521]-Validate-Loss:0.945, Acc:0.673
[2023-05-01 17:33:32.740552]-Train-Epoch:  4,  Loss: 0.792, Acc:0.719
[2023-05-01 17:33:36.444110]-Validate-Loss:0.735, Acc:0.742
[2023-05-01 17:33:49.384729]-Train-Epoch:  5,  Loss: 0.684, Acc:0.754
[2023-05-01 17:33:53.090158]-Validate-Loss:4.391, Acc:0.383
[2023-05-01 17:34:06.053314]-Train-Epoch:  6,  Loss: 0.643, Acc:0.774
[2023-05-01 17:34:09.799797]-Validate-Loss:2.560, Acc:0.506
[2023-05-01 17:34:22.749005]-Train-Epoch:  7,  Loss: 0.610, Acc:0.783
[2023-05-01 17:34:26.338020]-Validate-Loss:1.108, Acc:0.719
[2023-05-01 17:34:39.198717]-Train-Epoch:  8,  Loss: 0.508, Acc:0.814
[2023-05-01 17:34:42.866450]-Validate-Loss:0.573, Acc:0.815
[2023-05-01 17:34:55.898488]-Train-Epoch:  9,  Loss: 0.489, Acc:0.832
[2023-05-01 17:34:59.482832]-Validate-Loss:0.778, Acc:0.773
[2023-05-01 17:35:12.469623]-Train-Epoch: 10,  Loss: 0.499, Acc:0.825
[2023-05-01 17:35:16.198559]-Validate-Loss:0.400, Acc:0.858
[2023-05-01 17:35:28.978350]-Train-Epoch: 11,  Loss: 0.420, Acc:0.852
[2023-05-01 17:35:32.522513]-Validate-Loss:0.450, Acc:0.848
[2023-05-01 17:35:45.597766]-Train-Epoch: 12,  Loss: 0.410, Acc:0.873
[2023-05-01 17:35:49.298590]-Validate-Loss:0.995, Acc:0.781
[2023-05-01 17:36:02.275515]-Train-Epoch: 13,  Loss: 0.370, Acc:0.872
[2023-05-01 17:36:05.950068]-Validate-Loss:0.577, Acc:0.798
[2023-05-01 17:36:18.893541]-Train-Epoch: 14,  Loss: 0.360, Acc:0.870
[2023-05-01 17:36:22.485947]-Validate-Loss:1.391, Acc:0.773
[2023-05-01 17:36:35.457735]-Train-Epoch: 15,  Loss: 0.352, Acc:0.884
[2023-05-01 17:36:39.175819]-Validate-Loss:0.269, Acc:0.902
[2023-05-01 17:36:52.155924]-Train-Epoch: 16,  Loss: 0.328, Acc:0.892
[2023-05-01 17:36:55.828208]-Validate-Loss:0.665, Acc:0.854
[2023-05-01 17:37:08.748268]-Train-Epoch: 17,  Loss: 0.307, Acc:0.890
[2023-05-01 17:37:12.325864]-Validate-Loss:0.458, Acc:0.867
[2023-05-01 17:37:25.213131]-Train-Epoch: 18,  Loss: 0.289, Acc:0.895
[2023-05-01 17:37:28.929509]-Validate-Loss:0.722, Acc:0.844
[2023-05-01 17:37:41.913082]-Train-Epoch: 19,  Loss: 0.265, Acc:0.912
[2023-05-01 17:37:45.542401]-Validate-Loss:0.257, Acc:0.917
[2023-05-01 17:37:58.417004]-Train-Epoch: 20,  Loss: 0.268, Acc:0.905
[2023-05-01 17:38:02.092836]-Validate-Loss:0.560, Acc:0.838
[2023-05-01 17:38:14.952103]-Train-Epoch: 21,  Loss: 0.237, Acc:0.922
[2023-05-01 17:38:18.627568]-Validate-Loss:1.026, Acc:0.840
[2023-05-01 17:38:31.752453]-Train-Epoch: 22,  Loss: 0.203, Acc:0.936
[2023-05-01 17:38:35.448635]-Validate-Loss:0.258, Acc:0.917
[2023-05-01 17:38:48.359978]-Train-Epoch: 23,  Loss: 0.177, Acc:0.934
[2023-05-01 17:38:52.042086]-Validate-Loss:0.208, Acc:0.923
[2023-05-01 17:39:05.164288]-Train-Epoch: 24,  Loss: 0.216, Acc:0.929
[2023-05-01 17:39:08.855890]-Validate-Loss:0.211, Acc:0.933
[2023-05-01 17:39:21.858513]-Train-Epoch: 25,  Loss: 0.198, Acc:0.933
[2023-05-01 17:39:25.466338]-Validate-Loss:0.289, Acc:0.887
[2023-05-01 17:39:38.356881]-Train-Epoch: 26,  Loss: 0.230, Acc:0.914
[2023-05-01 17:39:42.006293]-Validate-Loss:0.221, Acc:0.935
[2023-05-01 17:39:54.792258]-Train-Epoch: 27,  Loss: 0.203, Acc:0.927
[2023-05-01 17:39:58.482568]-Validate-Loss:0.283, Acc:0.904
[2023-05-01 17:40:11.310880]-Train-Epoch: 28,  Loss: 0.191, Acc:0.932
[2023-05-01 17:40:14.948115]-Validate-Loss:0.206, Acc:0.933
[2023-05-01 17:40:28.107763]-Train-Epoch: 29,  Loss: 0.169, Acc:0.941
[2023-05-01 17:40:31.778052]-Validate-Loss:0.131, Acc:0.960
[2023-05-01 17:40:44.648756]-Train-Epoch: 30,  Loss: 0.168, Acc:0.941
[2023-05-01 17:40:48.220303]-Validate-Loss:0.143, Acc:0.950
[2023-05-01 17:40:48.226292]-Finished-Acc:0.960
