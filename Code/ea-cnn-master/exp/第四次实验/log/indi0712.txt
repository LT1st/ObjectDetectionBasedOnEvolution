[2023-05-02 05:14:48.122599]-Used GPU#0, worker name:Process-132[21068]
[2023-05-02 05:16:06.692876]-Train-Epoch:  1,  Loss: 1.404, Acc:0.448
[2023-05-02 05:16:19.252871]-Validate-Loss:1.562, Acc:0.552
[2023-05-02 05:17:30.475927]-Train-Epoch:  2,  Loss: 0.848, Acc:0.688
[2023-05-02 05:17:42.113783]-Validate-Loss:0.966, Acc:0.692
[2023-05-02 05:18:53.379085]-Train-Epoch:  3,  Loss: 0.706, Acc:0.725
[2023-05-02 05:19:05.032746]-Validate-Loss:1.337, Acc:0.758
[2023-05-02 05:20:16.120889]-Train-Epoch:  4,  Loss: 0.591, Acc:0.795
[2023-05-02 05:20:27.746476]-Validate-Loss:0.679, Acc:0.844
[2023-05-02 05:21:38.873532]-Train-Epoch:  5,  Loss: 0.514, Acc:0.818
[2023-05-02 05:21:50.414332]-Validate-Loss:0.951, Acc:0.827
[2023-05-02 05:23:01.537741]-Train-Epoch:  6,  Loss: 0.462, Acc:0.832
[2023-05-02 05:23:13.208859]-Validate-Loss:1.054, Acc:0.817
[2023-05-02 05:24:24.244594]-Train-Epoch:  7,  Loss: 0.399, Acc:0.859
[2023-05-02 05:24:35.908192]-Validate-Loss:0.754, Acc:0.833
[2023-05-02 05:25:47.073873]-Train-Epoch:  8,  Loss: 0.362, Acc:0.878
[2023-05-02 05:25:58.735021]-Validate-Loss:0.919, Acc:0.846
[2023-05-02 05:27:09.969750]-Train-Epoch:  9,  Loss: 0.343, Acc:0.866
[2023-05-02 05:27:21.611706]-Validate-Loss:0.665, Acc:0.852
[2023-05-02 05:28:32.703035]-Train-Epoch: 10,  Loss: 0.344, Acc:0.884
[2023-05-02 05:28:44.271744]-Validate-Loss:0.775, Acc:0.873
[2023-05-02 05:29:55.297120]-Train-Epoch: 11,  Loss: 0.274, Acc:0.902
[2023-05-02 05:30:06.969278]-Validate-Loss:0.909, Acc:0.896
[2023-05-02 05:31:18.138459]-Train-Epoch: 12,  Loss: 0.257, Acc:0.918
[2023-05-02 05:31:29.749213]-Validate-Loss:0.338, Acc:0.883
[2023-05-02 05:32:40.899904]-Train-Epoch: 13,  Loss: 0.234, Acc:0.922
[2023-05-02 05:32:52.516500]-Validate-Loss:0.461, Acc:0.869
[2023-05-02 05:34:03.763899]-Train-Epoch: 14,  Loss: 0.250, Acc:0.913
[2023-05-02 05:34:15.352795]-Validate-Loss:0.670, Acc:0.902
[2023-05-02 05:35:26.519006]-Train-Epoch: 15,  Loss: 0.203, Acc:0.928
[2023-05-02 05:35:38.114715]-Validate-Loss:0.508, Acc:0.900
[2023-05-02 05:36:49.398562]-Train-Epoch: 16,  Loss: 0.194, Acc:0.940
[2023-05-02 05:37:01.133459]-Validate-Loss:0.874, Acc:0.881
[2023-05-02 05:38:12.356421]-Train-Epoch: 17,  Loss: 0.238, Acc:0.913
[2023-05-02 05:38:24.035953]-Validate-Loss:0.583, Acc:0.888
[2023-05-02 05:39:35.503145]-Train-Epoch: 18,  Loss: 0.195, Acc:0.938
[2023-05-02 05:39:47.230997]-Validate-Loss:1.106, Acc:0.902
[2023-05-02 05:40:58.517784]-Train-Epoch: 19,  Loss: 0.216, Acc:0.930
[2023-05-02 05:41:10.184226]-Validate-Loss:0.499, Acc:0.925
[2023-05-02 05:42:21.396190]-Train-Epoch: 20,  Loss: 0.190, Acc:0.935
[2023-05-02 05:42:33.070127]-Validate-Loss:2.092, Acc:0.825
[2023-05-02 05:43:44.359371]-Train-Epoch: 21,  Loss: 0.191, Acc:0.938
[2023-05-02 05:43:56.329591]-Validate-Loss:1.598, Acc:0.852
[2023-05-02 05:45:07.405828]-Train-Epoch: 22,  Loss: 0.147, Acc:0.952
[2023-05-02 05:45:19.093431]-Validate-Loss:0.664, Acc:0.906
[2023-05-02 05:46:30.335481]-Train-Epoch: 23,  Loss: 0.156, Acc:0.947
[2023-05-02 05:46:42.005291]-Validate-Loss:0.621, Acc:0.913
[2023-05-02 05:47:52.972438]-Train-Epoch: 24,  Loss: 0.143, Acc:0.955
[2023-05-02 05:48:04.623190]-Validate-Loss:0.573, Acc:0.933
[2023-05-02 05:49:15.758245]-Train-Epoch: 25,  Loss: 0.160, Acc:0.949
[2023-05-02 05:49:27.468146]-Validate-Loss:0.480, Acc:0.919
[2023-05-02 05:50:38.777011]-Train-Epoch: 26,  Loss: 0.165, Acc:0.940
[2023-05-02 05:50:50.516318]-Validate-Loss:0.660, Acc:0.950
[2023-05-02 05:52:01.699803]-Train-Epoch: 27,  Loss: 0.143, Acc:0.955
[2023-05-02 05:52:13.304964]-Validate-Loss:0.993, Acc:0.869
[2023-05-02 05:53:24.445339]-Train-Epoch: 28,  Loss: 0.147, Acc:0.949
[2023-05-02 05:53:36.105932]-Validate-Loss:0.719, Acc:0.910
[2023-05-02 05:54:47.296665]-Train-Epoch: 29,  Loss: 0.172, Acc:0.943
[2023-05-02 05:54:58.968318]-Validate-Loss:0.844, Acc:0.892
[2023-05-02 05:56:10.088963]-Train-Epoch: 30,  Loss: 0.132, Acc:0.950
[2023-05-02 05:56:21.716183]-Validate-Loss:1.045, Acc:0.913
[2023-05-02 05:56:21.722171]-Finished-Acc:0.950
