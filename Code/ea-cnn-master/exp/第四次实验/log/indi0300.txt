[2023-05-01 17:58:53.644209]-Used GPU#0, worker name:Process-76[13132]
[2023-05-01 18:00:10.089834]-Train-Epoch:  1,  Loss: 1.480, Acc:0.381
[2023-05-01 18:00:22.395637]-Validate-Loss:1.976, Acc:0.575
[2023-05-01 18:01:31.661277]-Train-Epoch:  2,  Loss: 1.142, Acc:0.563
[2023-05-01 18:01:42.944570]-Validate-Loss:1.109, Acc:0.621
[2023-05-01 18:02:52.290457]-Train-Epoch:  3,  Loss: 1.047, Acc:0.583
[2023-05-01 18:03:03.611806]-Validate-Loss:0.912, Acc:0.704
[2023-05-01 18:04:12.945601]-Train-Epoch:  4,  Loss: 0.890, Acc:0.653
[2023-05-01 18:04:24.320112]-Validate-Loss:0.940, Acc:0.690
[2023-05-01 18:05:33.482170]-Train-Epoch:  5,  Loss: 0.861, Acc:0.670
[2023-05-01 18:05:44.765406]-Validate-Loss:1.020, Acc:0.706
[2023-05-01 18:06:54.097484]-Train-Epoch:  6,  Loss: 0.737, Acc:0.715
[2023-05-01 18:07:05.342700]-Validate-Loss:0.787, Acc:0.758
[2023-05-01 18:08:14.704286]-Train-Epoch:  7,  Loss: 0.685, Acc:0.745
[2023-05-01 18:08:26.167632]-Validate-Loss:0.683, Acc:0.765
[2023-05-01 18:09:35.536426]-Train-Epoch:  8,  Loss: 0.638, Acc:0.764
[2023-05-01 18:09:46.717885]-Validate-Loss:0.702, Acc:0.806
[2023-05-01 18:10:56.168003]-Train-Epoch:  9,  Loss: 0.598, Acc:0.793
[2023-05-01 18:11:07.421872]-Validate-Loss:0.500, Acc:0.844
[2023-05-01 18:12:17.019063]-Train-Epoch: 10,  Loss: 0.520, Acc:0.810
[2023-05-01 18:12:28.397922]-Validate-Loss:0.685, Acc:0.838
[2023-05-01 18:13:37.875967]-Train-Epoch: 11,  Loss: 0.506, Acc:0.811
[2023-05-01 18:13:49.338257]-Validate-Loss:0.487, Acc:0.862
[2023-05-01 18:14:58.724125]-Train-Epoch: 12,  Loss: 0.472, Acc:0.830
[2023-05-01 18:15:09.982093]-Validate-Loss:0.700, Acc:0.854
[2023-05-01 18:16:19.690849]-Train-Epoch: 13,  Loss: 0.430, Acc:0.844
[2023-05-01 18:16:31.133002]-Validate-Loss:0.330, Acc:0.894
[2023-05-01 18:17:40.609277]-Train-Epoch: 14,  Loss: 0.390, Acc:0.861
[2023-05-01 18:17:51.896511]-Validate-Loss:0.376, Acc:0.881
[2023-05-01 18:19:01.479848]-Train-Epoch: 15,  Loss: 0.321, Acc:0.891
[2023-05-01 18:19:12.827411]-Validate-Loss:0.270, Acc:0.937
[2023-05-01 18:20:22.248251]-Train-Epoch: 16,  Loss: 0.337, Acc:0.883
[2023-05-01 18:20:33.568088]-Validate-Loss:0.402, Acc:0.904
[2023-05-01 18:21:42.981075]-Train-Epoch: 17,  Loss: 0.282, Acc:0.909
[2023-05-01 18:21:54.254273]-Validate-Loss:0.325, Acc:0.906
[2023-05-01 18:23:03.802380]-Train-Epoch: 18,  Loss: 0.276, Acc:0.913
[2023-05-01 18:23:15.186659]-Validate-Loss:0.446, Acc:0.912
[2023-05-01 18:24:24.901259]-Train-Epoch: 19,  Loss: 0.239, Acc:0.920
[2023-05-01 18:24:36.200692]-Validate-Loss:0.393, Acc:0.923
[2023-05-01 18:25:45.671437]-Train-Epoch: 20,  Loss: 0.281, Acc:0.907
[2023-05-01 18:25:56.907634]-Validate-Loss:0.891, Acc:0.881
[2023-05-01 18:27:06.477174]-Train-Epoch: 21,  Loss: 0.242, Acc:0.916
[2023-05-01 18:27:17.694622]-Validate-Loss:0.661, Acc:0.865
[2023-05-01 18:28:27.200597]-Train-Epoch: 22,  Loss: 0.187, Acc:0.939
[2023-05-01 18:28:38.441193]-Validate-Loss:0.268, Acc:0.937
[2023-05-01 18:29:47.987342]-Train-Epoch: 23,  Loss: 0.176, Acc:0.938
[2023-05-01 18:29:59.427524]-Validate-Loss:0.806, Acc:0.883
[2023-05-01 18:31:08.778066]-Train-Epoch: 24,  Loss: 0.199, Acc:0.930
[2023-05-01 18:31:20.247271]-Validate-Loss:0.555, Acc:0.910
[2023-05-01 18:32:29.699099]-Train-Epoch: 25,  Loss: 0.150, Acc:0.953
[2023-05-01 18:32:40.998998]-Validate-Loss:0.457, Acc:0.925
[2023-05-01 18:33:50.441413]-Train-Epoch: 26,  Loss: 0.180, Acc:0.940
[2023-05-01 18:34:01.741585]-Validate-Loss:0.105, Acc:0.963
[2023-05-01 18:35:11.216078]-Train-Epoch: 27,  Loss: 0.185, Acc:0.934
[2023-05-01 18:35:22.554686]-Validate-Loss:0.228, Acc:0.956
[2023-05-01 18:36:33.207019]-Train-Epoch: 28,  Loss: 0.141, Acc:0.952
[2023-05-01 18:36:44.557840]-Validate-Loss:0.398, Acc:0.929
[2023-05-01 18:37:54.180854]-Train-Epoch: 29,  Loss: 0.168, Acc:0.940
[2023-05-01 18:38:05.599533]-Validate-Loss:0.286, Acc:0.958
[2023-05-01 18:39:15.151815]-Train-Epoch: 30,  Loss: 0.144, Acc:0.950
[2023-05-01 18:39:26.462094]-Validate-Loss:0.315, Acc:0.919
[2023-05-01 18:39:26.469084]-Finished-Acc:0.963
