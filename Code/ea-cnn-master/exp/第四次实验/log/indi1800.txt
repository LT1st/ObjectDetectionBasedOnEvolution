[2023-05-03 04:15:46.954629]-Used GPU#0, worker name:Process-262[21880]
[2023-05-03 04:16:10.773934]-Train-Epoch:  1,  Loss: 3.183, Acc:0.331
[2023-05-03 04:16:15.821527]-Validate-Loss:3.109, Acc:0.413
[2023-05-03 04:16:33.537637]-Train-Epoch:  2,  Loss: 1.787, Acc:0.472
[2023-05-03 04:16:37.904075]-Validate-Loss:1.227, Acc:0.562
[2023-05-03 04:16:55.221600]-Train-Epoch:  3,  Loss: 1.333, Acc:0.574
[2023-05-03 04:16:59.506858]-Validate-Loss:1.759, Acc:0.569
[2023-05-03 04:17:16.808208]-Train-Epoch:  4,  Loss: 1.107, Acc:0.625
[2023-05-03 04:17:21.104389]-Validate-Loss:0.931, Acc:0.658
[2023-05-03 04:17:38.431877]-Train-Epoch:  5,  Loss: 1.013, Acc:0.633
[2023-05-03 04:17:42.708911]-Validate-Loss:1.481, Acc:0.658
[2023-05-03 04:18:00.109968]-Train-Epoch:  6,  Loss: 0.856, Acc:0.699
[2023-05-03 04:18:04.463963]-Validate-Loss:0.930, Acc:0.688
[2023-05-03 04:18:21.899739]-Train-Epoch:  7,  Loss: 0.822, Acc:0.729
[2023-05-03 04:18:26.135642]-Validate-Loss:0.881, Acc:0.690
[2023-05-03 04:18:43.628840]-Train-Epoch:  8,  Loss: 0.831, Acc:0.706
[2023-05-03 04:18:47.962652]-Validate-Loss:0.670, Acc:0.775
[2023-05-03 04:19:05.452560]-Train-Epoch:  9,  Loss: 0.680, Acc:0.763
[2023-05-03 04:19:09.702794]-Validate-Loss:0.630, Acc:0.762
[2023-05-03 04:19:27.151504]-Train-Epoch: 10,  Loss: 0.609, Acc:0.771
[2023-05-03 04:19:31.431097]-Validate-Loss:0.900, Acc:0.750
[2023-05-03 04:19:48.842406]-Train-Epoch: 11,  Loss: 0.601, Acc:0.797
[2023-05-03 04:19:53.257713]-Validate-Loss:0.468, Acc:0.840
[2023-05-03 04:20:10.570004]-Train-Epoch: 12,  Loss: 0.577, Acc:0.795
[2023-05-03 04:20:14.844809]-Validate-Loss:0.719, Acc:0.767
[2023-05-03 04:20:32.346900]-Train-Epoch: 13,  Loss: 0.532, Acc:0.810
[2023-05-03 04:20:36.623349]-Validate-Loss:0.583, Acc:0.812
[2023-05-03 04:20:54.012550]-Train-Epoch: 14,  Loss: 0.492, Acc:0.823
[2023-05-03 04:20:58.275787]-Validate-Loss:0.471, Acc:0.867
[2023-05-03 04:21:15.654380]-Train-Epoch: 15,  Loss: 0.511, Acc:0.823
[2023-05-03 04:21:19.906493]-Validate-Loss:0.349, Acc:0.869
[2023-05-03 04:21:37.299100]-Train-Epoch: 16,  Loss: 0.425, Acc:0.854
[2023-05-03 04:21:41.633159]-Validate-Loss:0.401, Acc:0.865
[2023-05-03 04:21:58.912567]-Train-Epoch: 17,  Loss: 0.424, Acc:0.856
[2023-05-03 04:22:03.177060]-Validate-Loss:0.461, Acc:0.833
[2023-05-03 04:22:20.554553]-Train-Epoch: 18,  Loss: 0.368, Acc:0.883
[2023-05-03 04:22:24.794655]-Validate-Loss:0.410, Acc:0.846
[2023-05-03 04:22:42.146490]-Train-Epoch: 19,  Loss: 0.414, Acc:0.863
[2023-05-03 04:22:46.371703]-Validate-Loss:0.568, Acc:0.823
[2023-05-03 04:23:03.722302]-Train-Epoch: 20,  Loss: 0.318, Acc:0.888
[2023-05-03 04:23:08.035579]-Validate-Loss:0.241, Acc:0.910
[2023-05-03 04:23:25.289006]-Train-Epoch: 21,  Loss: 0.319, Acc:0.893
[2023-05-03 04:23:29.533835]-Validate-Loss:0.266, Acc:0.912
[2023-05-03 04:23:46.869742]-Train-Epoch: 22,  Loss: 0.352, Acc:0.873
[2023-05-03 04:23:51.121870]-Validate-Loss:0.478, Acc:0.869
[2023-05-03 04:24:08.524936]-Train-Epoch: 23,  Loss: 0.260, Acc:0.908
[2023-05-03 04:24:12.799171]-Validate-Loss:0.323, Acc:0.894
[2023-05-03 04:24:30.126189]-Train-Epoch: 24,  Loss: 0.201, Acc:0.931
[2023-05-03 04:24:34.379619]-Validate-Loss:0.309, Acc:0.913
[2023-05-03 04:24:51.627075]-Train-Epoch: 25,  Loss: 0.237, Acc:0.917
[2023-05-03 04:24:55.810261]-Validate-Loss:0.212, Acc:0.923
[2023-05-03 04:25:13.211582]-Train-Epoch: 26,  Loss: 0.219, Acc:0.923
[2023-05-03 04:25:17.695039]-Validate-Loss:0.293, Acc:0.902
[2023-05-03 04:25:35.238039]-Train-Epoch: 27,  Loss: 0.211, Acc:0.926
[2023-05-03 04:25:39.498640]-Validate-Loss:0.336, Acc:0.908
[2023-05-03 04:25:56.923355]-Train-Epoch: 28,  Loss: 0.235, Acc:0.920
[2023-05-03 04:26:01.201368]-Validate-Loss:0.210, Acc:0.923
[2023-05-03 04:26:18.618332]-Train-Epoch: 29,  Loss: 0.202, Acc:0.929
[2023-05-03 04:26:22.925507]-Validate-Loss:0.491, Acc:0.900
[2023-05-03 04:26:40.247084]-Train-Epoch: 30,  Loss: 0.208, Acc:0.938
[2023-05-03 04:26:44.517162]-Validate-Loss:0.183, Acc:0.938
[2023-05-03 04:26:44.523154]-Finished-Acc:0.938
