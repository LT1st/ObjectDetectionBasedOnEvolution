[2023-05-01 18:36:40.733715]-Used GPU#1, worker name:Process-80[11040]
[2023-05-01 18:37:13.031184]-Train-Epoch:  1,  Loss: 1.600, Acc:0.388
[2023-05-01 18:37:19.635821]-Validate-Loss:1.590, Acc:0.512
[2023-05-01 18:37:46.042299]-Train-Epoch:  2,  Loss: 1.204, Acc:0.548
[2023-05-01 18:37:51.484174]-Validate-Loss:1.596, Acc:0.617
[2023-05-01 18:38:17.772120]-Train-Epoch:  3,  Loss: 1.002, Acc:0.640
[2023-05-01 18:38:23.164508]-Validate-Loss:1.689, Acc:0.662
[2023-05-01 18:38:49.437464]-Train-Epoch:  4,  Loss: 0.914, Acc:0.670
[2023-05-01 18:38:54.867329]-Validate-Loss:1.318, Acc:0.717
[2023-05-01 18:39:21.346336]-Train-Epoch:  5,  Loss: 0.761, Acc:0.720
[2023-05-01 18:39:26.844055]-Validate-Loss:0.900, Acc:0.754
[2023-05-01 18:39:53.533451]-Train-Epoch:  6,  Loss: 0.704, Acc:0.741
[2023-05-01 18:39:59.042060]-Validate-Loss:0.867, Acc:0.698
[2023-05-01 18:40:25.252907]-Train-Epoch:  7,  Loss: 0.663, Acc:0.770
[2023-05-01 18:40:30.674596]-Validate-Loss:1.491, Acc:0.775
[2023-05-01 18:40:56.908490]-Train-Epoch:  8,  Loss: 0.563, Acc:0.805
[2023-05-01 18:41:02.390906]-Validate-Loss:1.812, Acc:0.708
[2023-05-01 18:41:28.745351]-Train-Epoch:  9,  Loss: 0.516, Acc:0.823
[2023-05-01 18:41:34.391230]-Validate-Loss:2.133, Acc:0.688
[2023-05-01 18:42:00.679166]-Train-Epoch: 10,  Loss: 0.456, Acc:0.845
[2023-05-01 18:42:06.247297]-Validate-Loss:1.032, Acc:0.877
[2023-05-01 18:42:32.677978]-Train-Epoch: 11,  Loss: 0.436, Acc:0.835
[2023-05-01 18:42:38.208516]-Validate-Loss:0.954, Acc:0.815
[2023-05-01 18:43:04.563251]-Train-Epoch: 12,  Loss: 0.396, Acc:0.862
[2023-05-01 18:43:10.061088]-Validate-Loss:0.815, Acc:0.904
[2023-05-01 18:43:36.485064]-Train-Epoch: 13,  Loss: 0.360, Acc:0.870
[2023-05-01 18:43:41.923933]-Validate-Loss:0.827, Acc:0.871
[2023-05-01 18:44:08.240160]-Train-Epoch: 14,  Loss: 0.283, Acc:0.898
[2023-05-01 18:44:13.742426]-Validate-Loss:0.716, Acc:0.890
[2023-05-01 18:44:40.040086]-Train-Epoch: 15,  Loss: 0.293, Acc:0.902
[2023-05-01 18:44:45.537320]-Validate-Loss:1.365, Acc:0.892
[2023-05-01 18:45:11.993822]-Train-Epoch: 16,  Loss: 0.260, Acc:0.909
[2023-05-01 18:45:17.554535]-Validate-Loss:0.863, Acc:0.881
[2023-05-01 18:45:43.794241]-Train-Epoch: 17,  Loss: 0.253, Acc:0.907
[2023-05-01 18:45:49.326385]-Validate-Loss:0.317, Acc:0.925
[2023-05-01 18:46:15.750994]-Train-Epoch: 18,  Loss: 0.254, Acc:0.913
[2023-05-01 18:46:21.196484]-Validate-Loss:1.175, Acc:0.892
[2023-05-01 18:46:47.599140]-Train-Epoch: 19,  Loss: 0.218, Acc:0.926
[2023-05-01 18:46:53.047632]-Validate-Loss:0.948, Acc:0.910
[2023-05-01 18:47:20.038657]-Train-Epoch: 20,  Loss: 0.188, Acc:0.936
[2023-05-01 18:47:25.647617]-Validate-Loss:0.601, Acc:0.927
[2023-05-01 18:47:52.054274]-Train-Epoch: 21,  Loss: 0.182, Acc:0.936
[2023-05-01 18:47:57.505081]-Validate-Loss:0.953, Acc:0.927
[2023-05-01 18:48:23.713852]-Train-Epoch: 22,  Loss: 0.163, Acc:0.946
[2023-05-01 18:48:29.090657]-Validate-Loss:0.540, Acc:0.915
[2023-05-01 18:48:55.358634]-Train-Epoch: 23,  Loss: 0.166, Acc:0.948
[2023-05-01 18:49:00.910381]-Validate-Loss:1.887, Acc:0.921
[2023-05-01 18:49:27.210326]-Train-Epoch: 24,  Loss: 0.138, Acc:0.955
[2023-05-01 18:49:32.662443]-Validate-Loss:2.048, Acc:0.869
[2023-05-01 18:49:58.895981]-Train-Epoch: 25,  Loss: 0.142, Acc:0.956
[2023-05-01 18:50:04.417180]-Validate-Loss:0.844, Acc:0.913
[2023-05-01 18:50:30.655780]-Train-Epoch: 26,  Loss: 0.113, Acc:0.963
[2023-05-01 18:50:36.194210]-Validate-Loss:0.648, Acc:0.827
[2023-05-01 18:51:02.470620]-Train-Epoch: 27,  Loss: 0.169, Acc:0.947
[2023-05-01 18:51:07.826050]-Validate-Loss:0.432, Acc:0.937
[2023-05-01 18:51:34.102718]-Train-Epoch: 28,  Loss: 0.141, Acc:0.959
[2023-05-01 18:51:39.488468]-Validate-Loss:0.461, Acc:0.929
[2023-05-01 18:52:05.731009]-Train-Epoch: 29,  Loss: 0.121, Acc:0.957
[2023-05-01 18:52:11.162709]-Validate-Loss:0.790, Acc:0.942
[2023-05-01 18:52:37.453331]-Train-Epoch: 30,  Loss: 0.128, Acc:0.957
[2023-05-01 18:52:42.806323]-Validate-Loss:0.963, Acc:0.906
[2023-05-01 18:52:42.812313]-Finished-Acc:0.942
