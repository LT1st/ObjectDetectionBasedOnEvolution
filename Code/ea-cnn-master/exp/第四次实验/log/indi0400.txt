[2023-05-01 20:42:48.831666]-Used GPU#0, worker name:Process-90[20256]
[2023-05-01 20:43:03.734163]-Train-Epoch:  1,  Loss: 1.431, Acc:0.427
[2023-05-01 20:43:07.974333]-Validate-Loss:1.679, Acc:0.590
[2023-05-01 20:43:18.888742]-Train-Epoch:  2,  Loss: 1.121, Acc:0.587
[2023-05-01 20:43:22.386064]-Validate-Loss:1.415, Acc:0.648
[2023-05-01 20:43:33.218875]-Train-Epoch:  3,  Loss: 0.972, Acc:0.627
[2023-05-01 20:43:36.716774]-Validate-Loss:1.399, Acc:0.660
[2023-05-01 20:43:47.476207]-Train-Epoch:  4,  Loss: 0.924, Acc:0.645
[2023-05-01 20:43:50.981928]-Validate-Loss:1.765, Acc:0.621
[2023-05-01 20:44:01.822985]-Train-Epoch:  5,  Loss: 0.849, Acc:0.673
[2023-05-01 20:44:05.308908]-Validate-Loss:0.981, Acc:0.652
[2023-05-01 20:44:16.266740]-Train-Epoch:  6,  Loss: 0.763, Acc:0.726
[2023-05-01 20:44:19.778865]-Validate-Loss:1.238, Acc:0.656
[2023-05-01 20:44:30.627208]-Train-Epoch:  7,  Loss: 0.678, Acc:0.745
[2023-05-01 20:44:34.128707]-Validate-Loss:0.622, Acc:0.815
[2023-05-01 20:44:45.000494]-Train-Epoch:  8,  Loss: 0.607, Acc:0.768
[2023-05-01 20:44:48.532371]-Validate-Loss:0.664, Acc:0.788
[2023-05-01 20:44:59.435111]-Train-Epoch:  9,  Loss: 0.562, Acc:0.792
[2023-05-01 20:45:02.912820]-Validate-Loss:0.649, Acc:0.823
[2023-05-01 20:45:13.777729]-Train-Epoch: 10,  Loss: 0.563, Acc:0.809
[2023-05-01 20:45:17.293842]-Validate-Loss:0.441, Acc:0.829
[2023-05-01 20:45:28.214992]-Train-Epoch: 11,  Loss: 0.505, Acc:0.819
[2023-05-01 20:45:31.718469]-Validate-Loss:0.491, Acc:0.779
[2023-05-01 20:45:42.603899]-Train-Epoch: 12,  Loss: 0.481, Acc:0.821
[2023-05-01 20:45:46.091977]-Validate-Loss:0.634, Acc:0.835
[2023-05-01 20:45:56.881633]-Train-Epoch: 13,  Loss: 0.446, Acc:0.840
[2023-05-01 20:46:00.498081]-Validate-Loss:0.471, Acc:0.825
[2023-05-01 20:46:11.411390]-Train-Epoch: 14,  Loss: 0.454, Acc:0.834
[2023-05-01 20:46:14.881227]-Validate-Loss:0.514, Acc:0.833
[2023-05-01 20:46:25.667766]-Train-Epoch: 15,  Loss: 0.428, Acc:0.839
[2023-05-01 20:46:29.091429]-Validate-Loss:1.017, Acc:0.835
[2023-05-01 20:46:40.037886]-Train-Epoch: 16,  Loss: 0.407, Acc:0.844
[2023-05-01 20:46:43.537831]-Validate-Loss:0.665, Acc:0.846
[2023-05-01 20:46:54.408843]-Train-Epoch: 17,  Loss: 0.391, Acc:0.859
[2023-05-01 20:46:57.880982]-Validate-Loss:0.551, Acc:0.838
[2023-05-01 20:47:08.803289]-Train-Epoch: 18,  Loss: 0.401, Acc:0.858
[2023-05-01 20:47:12.312566]-Validate-Loss:0.298, Acc:0.894
[2023-05-01 20:47:23.185211]-Train-Epoch: 19,  Loss: 0.366, Acc:0.872
[2023-05-01 20:47:26.669928]-Validate-Loss:0.314, Acc:0.896
[2023-05-01 20:47:37.591182]-Train-Epoch: 20,  Loss: 0.383, Acc:0.867
[2023-05-01 20:47:41.123073]-Validate-Loss:0.512, Acc:0.848
[2023-05-01 20:47:51.991626]-Train-Epoch: 21,  Loss: 0.373, Acc:0.864
[2023-05-01 20:47:55.472265]-Validate-Loss:0.495, Acc:0.910
[2023-05-01 20:48:06.208661]-Train-Epoch: 22,  Loss: 0.295, Acc:0.889
[2023-05-01 20:48:09.721315]-Validate-Loss:0.471, Acc:0.902
[2023-05-01 20:48:20.594634]-Train-Epoch: 23,  Loss: 0.304, Acc:0.891
[2023-05-01 20:48:24.059052]-Validate-Loss:0.266, Acc:0.885
[2023-05-01 20:48:34.987144]-Train-Epoch: 24,  Loss: 0.260, Acc:0.910
[2023-05-01 20:48:38.490898]-Validate-Loss:0.278, Acc:0.906
[2023-05-01 20:48:49.421982]-Train-Epoch: 25,  Loss: 0.270, Acc:0.902
[2023-05-01 20:48:53.039386]-Validate-Loss:0.276, Acc:0.923
[2023-05-01 20:49:03.768680]-Train-Epoch: 26,  Loss: 0.282, Acc:0.892
[2023-05-01 20:49:07.249481]-Validate-Loss:0.507, Acc:0.898
[2023-05-01 20:49:18.213013]-Train-Epoch: 27,  Loss: 0.283, Acc:0.899
[2023-05-01 20:49:22.084966]-Validate-Loss:0.225, Acc:0.923
[2023-05-01 20:49:32.984453]-Train-Epoch: 28,  Loss: 0.286, Acc:0.907
[2023-05-01 20:49:36.455157]-Validate-Loss:0.350, Acc:0.885
[2023-05-01 20:49:47.284720]-Train-Epoch: 29,  Loss: 0.258, Acc:0.909
[2023-05-01 20:49:50.840794]-Validate-Loss:0.376, Acc:0.912
[2023-05-01 20:50:01.763432]-Train-Epoch: 30,  Loss: 0.271, Acc:0.902
[2023-05-01 20:50:05.215861]-Validate-Loss:0.358, Acc:0.919
[2023-05-01 20:50:05.221850]-Finished-Acc:0.923
