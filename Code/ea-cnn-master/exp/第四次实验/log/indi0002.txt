[2023-05-01 09:52:42.695288]-Used GPU#0, worker name:Process-23[3940]
[2023-05-01 09:53:59.053628]-Train-Epoch:  1,  Loss: 1.521, Acc:0.370
[2023-05-01 09:54:11.414890]-Validate-Loss:1.526, Acc:0.554
[2023-05-01 09:55:19.663334]-Train-Epoch:  2,  Loss: 1.131, Acc:0.568
[2023-05-01 09:55:30.886947]-Validate-Loss:1.188, Acc:0.667
[2023-05-01 09:56:39.146108]-Train-Epoch:  3,  Loss: 0.953, Acc:0.637
[2023-05-01 09:56:50.534918]-Validate-Loss:0.752, Acc:0.738
[2023-05-01 09:57:58.933290]-Train-Epoch:  4,  Loss: 0.799, Acc:0.684
[2023-05-01 09:58:10.181793]-Validate-Loss:1.002, Acc:0.733
[2023-05-01 09:59:18.721369]-Train-Epoch:  5,  Loss: 0.798, Acc:0.696
[2023-05-01 09:59:30.027020]-Validate-Loss:1.067, Acc:0.771
[2023-05-01 10:00:38.447864]-Train-Epoch:  6,  Loss: 0.684, Acc:0.753
[2023-05-01 10:00:49.792969]-Validate-Loss:0.474, Acc:0.879
[2023-05-01 10:01:58.201069]-Train-Epoch:  7,  Loss: 0.548, Acc:0.802
[2023-05-01 10:02:09.415983]-Validate-Loss:0.432, Acc:0.885
[2023-05-01 10:03:17.956463]-Train-Epoch:  8,  Loss: 0.534, Acc:0.816
[2023-05-01 10:03:29.134041]-Validate-Loss:0.555, Acc:0.833
[2023-05-01 10:04:37.705784]-Train-Epoch:  9,  Loss: 0.433, Acc:0.844
[2023-05-01 10:04:48.929112]-Validate-Loss:0.495, Acc:0.887
[2023-05-01 10:05:57.327623]-Train-Epoch: 10,  Loss: 0.454, Acc:0.842
[2023-05-01 10:06:08.529306]-Validate-Loss:0.262, Acc:0.921
[2023-05-01 10:07:17.091522]-Train-Epoch: 11,  Loss: 0.368, Acc:0.870
[2023-05-01 10:07:28.439125]-Validate-Loss:0.421, Acc:0.912
[2023-05-01 10:08:36.911326]-Train-Epoch: 12,  Loss: 0.438, Acc:0.850
[2023-05-01 10:08:48.246326]-Validate-Loss:0.384, Acc:0.892
[2023-05-01 10:09:56.668477]-Train-Epoch: 13,  Loss: 0.317, Acc:0.884
[2023-05-01 10:10:07.972600]-Validate-Loss:0.296, Acc:0.921
[2023-05-01 10:11:16.475830]-Train-Epoch: 14,  Loss: 0.326, Acc:0.887
[2023-05-01 10:11:27.738440]-Validate-Loss:0.245, Acc:0.929
[2023-05-01 10:12:36.264485]-Train-Epoch: 15,  Loss: 0.300, Acc:0.902
[2023-05-01 10:12:47.621489]-Validate-Loss:0.183, Acc:0.942
[2023-05-01 10:13:56.232849]-Train-Epoch: 16,  Loss: 0.298, Acc:0.892
[2023-05-01 10:14:07.432686]-Validate-Loss:0.416, Acc:0.910
[2023-05-01 10:15:15.994737]-Train-Epoch: 17,  Loss: 0.270, Acc:0.909
[2023-05-01 10:15:27.227849]-Validate-Loss:0.203, Acc:0.938
[2023-05-01 10:16:35.966748]-Train-Epoch: 18,  Loss: 0.246, Acc:0.914
[2023-05-01 10:16:47.304342]-Validate-Loss:0.280, Acc:0.923
[2023-05-01 10:17:55.811917]-Train-Epoch: 19,  Loss: 0.216, Acc:0.933
[2023-05-01 10:18:07.085085]-Validate-Loss:0.138, Acc:0.973
[2023-05-01 10:19:15.490002]-Train-Epoch: 20,  Loss: 0.235, Acc:0.918
[2023-05-01 10:19:26.825003]-Validate-Loss:0.238, Acc:0.921
[2023-05-01 10:20:35.467503]-Train-Epoch: 21,  Loss: 0.237, Acc:0.920
[2023-05-01 10:20:46.766403]-Validate-Loss:0.176, Acc:0.931
[2023-05-01 10:21:55.509465]-Train-Epoch: 22,  Loss: 0.227, Acc:0.925
[2023-05-01 10:22:06.918546]-Validate-Loss:0.161, Acc:0.948
[2023-05-01 10:23:15.468789]-Train-Epoch: 23,  Loss: 0.181, Acc:0.941
[2023-05-01 10:23:26.983892]-Validate-Loss:0.103, Acc:0.965
[2023-05-01 10:24:35.735201]-Train-Epoch: 24,  Loss: 0.184, Acc:0.938
[2023-05-01 10:24:46.916577]-Validate-Loss:0.105, Acc:0.967
[2023-05-01 10:25:55.553965]-Train-Epoch: 25,  Loss: 0.162, Acc:0.951
[2023-05-01 10:26:06.907638]-Validate-Loss:0.234, Acc:0.948
[2023-05-01 10:27:15.417829]-Train-Epoch: 26,  Loss: 0.183, Acc:0.935
[2023-05-01 10:27:26.694428]-Validate-Loss:0.250, Acc:0.944
[2023-05-01 10:28:35.294043]-Train-Epoch: 27,  Loss: 0.151, Acc:0.947
[2023-05-01 10:28:46.489505]-Validate-Loss:0.116, Acc:0.948
[2023-05-01 10:29:55.189586]-Train-Epoch: 28,  Loss: 0.156, Acc:0.946
[2023-05-01 10:30:06.450870]-Validate-Loss:0.162, Acc:0.942
[2023-05-01 10:31:15.108556]-Train-Epoch: 29,  Loss: 0.138, Acc:0.955
[2023-05-01 10:31:26.428649]-Validate-Loss:0.114, Acc:0.954
[2023-05-01 10:32:35.124144]-Train-Epoch: 30,  Loss: 0.136, Acc:0.958
[2023-05-01 10:32:46.625449]-Validate-Loss:0.071, Acc:0.979
[2023-05-01 10:32:46.633436]-Finished-Acc:0.979
